{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q4gSqDnOaJ7W"
      },
      "source": [
        "<img align=center src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcT2RkpDnU0khR-RsIgLQcCKUMwM3EbWiFN_5Q&usqp=CAU\"></img>\n",
        "<h2 align=center> Punctuation Restoration using BiLSTMs with Keras</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4IU4QuHO33M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fdo8oAodagwo"
      },
      "source": [
        "### Task 1: Project Overview and Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oLK7Y1jiNXDa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b494d738-c5b8-4480-a830-66342d3ceec3"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(0)\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "print('Tensorflow version:', tf.__version__)\n",
        "print('GPU detected:', tf.config.list_physical_devices('GPU'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.2.0\n",
            "GPU detected: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4N_AW6lMbB5N"
      },
      "source": [
        "### Task 2: Load and Explore the TED transcription Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_4DvshIOxEB",
        "colab_type": "text"
      },
      "source": [
        "*Essential info about punctuation tags*:\n",
        "- , = comma\n",
        "- ! = exclamation mark\n",
        "- . = dot\n",
        "- ? = question mark\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bJ3EJiOZ4-H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "40a7c718-110a-4c2e-90da-257f53d60dca"
      },
      "source": [
        "transcript_df = pd.read_csv(\"/content/drive/My Drive/projects/Punctuation Restoration/transcripts.csv\", encoding=\"utf-8\")\n",
        "transcript_df = transcript_df.fillna(method=\"ffill\")\n",
        "transcript_df.head(20)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transcript</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Good morning. How are you?(Laughter)It's been ...</td>\n",
              "      <td>https://www.ted.com/talks/ken_robinson_says_sc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
              "      <td>https://www.ted.com/talks/al_gore_on_averting_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(Music: \"The Sound of Silence,\" Simon &amp; Garfun...</td>\n",
              "      <td>https://www.ted.com/talks/david_pogue_says_sim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you're here today â€” and I'm very happy that...</td>\n",
              "      <td>https://www.ted.com/talks/majora_carter_s_tale...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>About 10 years ago, I took on the task to teac...</td>\n",
              "      <td>https://www.ted.com/talks/hans_rosling_shows_t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Thank you. I have to tell you I'm both challen...</td>\n",
              "      <td>https://www.ted.com/talks/tony_robbins_asks_wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>On September 10, the morning of my seventh bir...</td>\n",
              "      <td>https://www.ted.com/talks/julia_sweeney_on_let...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>I'm going to present three projects in rapid f...</td>\n",
              "      <td>https://www.ted.com/talks/joshua_prince_ramus_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>It's wonderful to be back. I love this wonderf...</td>\n",
              "      <td>https://www.ted.com/talks/dan_dennett_s_respon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I'm often asked, \"What surprised you about the...</td>\n",
              "      <td>https://www.ted.com/talks/rick_warren_on_a_lif...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>I'm going to take you on a journey very quickl...</td>\n",
              "      <td>https://www.ted.com/talks/cameron_sinclair_on_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>I can't help but this wish: to think about whe...</td>\n",
              "      <td>https://www.ted.com/talks/jehane_noujaim_inspi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>I'm the luckiest guy in the world. I got to se...</td>\n",
              "      <td>https://www.ted.com/talks/larry_brilliant_want...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>I'm really excited to be here today. I'll show...</td>\n",
              "      <td>https://www.ted.com/talks/jeff_han_demos_his_b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>I've been at MIT for 44 years. I went to TED I...</td>\n",
              "      <td>https://www.ted.com/talks/nicholas_negroponte_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>(Music)(Music ends)(Applause)(Applause ends)Hi...</td>\n",
              "      <td>https://www.ted.com/talks/sirena_huang_dazzles...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>(Music)(Music ends)(Applause)Thank you!(Applau...</td>\n",
              "      <td>https://www.ted.com/talks/jennifer_lin_improvs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>In terms of invention, I'd like to tell you th...</td>\n",
              "      <td>https://www.ted.com/talks/amy_smith_shares_sim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>My name is Lovegrove. I only know nine Lovegro...</td>\n",
              "      <td>https://www.ted.com/talks/ross_lovegrove_share...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Charles Van Doren, who was later a senior edit...</td>\n",
              "      <td>https://www.ted.com/talks/jimmy_wales_on_the_b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           transcript                                                url\n",
              "0   Good morning. How are you?(Laughter)It's been ...  https://www.ted.com/talks/ken_robinson_says_sc...\n",
              "1   Thank you so much, Chris. And it's truly a gre...  https://www.ted.com/talks/al_gore_on_averting_...\n",
              "2   (Music: \"The Sound of Silence,\" Simon & Garfun...  https://www.ted.com/talks/david_pogue_says_sim...\n",
              "3   If you're here today â€” and I'm very happy that...  https://www.ted.com/talks/majora_carter_s_tale...\n",
              "4   About 10 years ago, I took on the task to teac...  https://www.ted.com/talks/hans_rosling_shows_t...\n",
              "5   Thank you. I have to tell you I'm both challen...  https://www.ted.com/talks/tony_robbins_asks_wh...\n",
              "6   On September 10, the morning of my seventh bir...  https://www.ted.com/talks/julia_sweeney_on_let...\n",
              "7   I'm going to present three projects in rapid f...  https://www.ted.com/talks/joshua_prince_ramus_...\n",
              "8   It's wonderful to be back. I love this wonderf...  https://www.ted.com/talks/dan_dennett_s_respon...\n",
              "9   I'm often asked, \"What surprised you about the...  https://www.ted.com/talks/rick_warren_on_a_lif...\n",
              "10  I'm going to take you on a journey very quickl...  https://www.ted.com/talks/cameron_sinclair_on_...\n",
              "11  I can't help but this wish: to think about whe...  https://www.ted.com/talks/jehane_noujaim_inspi...\n",
              "12  I'm the luckiest guy in the world. I got to se...  https://www.ted.com/talks/larry_brilliant_want...\n",
              "13  I'm really excited to be here today. I'll show...  https://www.ted.com/talks/jeff_han_demos_his_b...\n",
              "14  I've been at MIT for 44 years. I went to TED I...  https://www.ted.com/talks/nicholas_negroponte_...\n",
              "15  (Music)(Music ends)(Applause)(Applause ends)Hi...  https://www.ted.com/talks/sirena_huang_dazzles...\n",
              "16  (Music)(Music ends)(Applause)Thank you!(Applau...  https://www.ted.com/talks/jennifer_lin_improvs...\n",
              "17  In terms of invention, I'd like to tell you th...  https://www.ted.com/talks/amy_smith_shares_sim...\n",
              "18  My name is Lovegrove. I only know nine Lovegro...  https://www.ted.com/talks/ross_lovegrove_share...\n",
              "19  Charles Van Doren, who was later a senior edit...  https://www.ted.com/talks/jimmy_wales_on_the_b..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKmDzK9qaTKb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "5ae34463-9ff2-4cc4-eb99-8d26bab79fc8"
      },
      "source": [
        "%time transcript_df.transcript = transcript_df.transcript.apply(lambda x: re.sub(r'\\([^)]*\\)', ' ', x))\n",
        "%time transcript_df.transcript = transcript_df.transcript.apply(lambda x: re.sub(r'(?<=[.,?!])(?=[^\\s])', ' ', x))\n",
        "%time transcript_df.transcript = transcript_df.transcript.apply(lambda x: x.replace('\"', ''))\n",
        "%time transcript_df.transcript = transcript_df.transcript.apply(lambda x: x.replace(\"'\", ''))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 47.1 ms, sys: 16.8 ms, total: 64 ms\n",
            "Wall time: 64.4 ms\n",
            "CPU times: user 729 ms, sys: 7.05 ms, total: 736 ms\n",
            "Wall time: 740 ms\n",
            "CPU times: user 37.3 ms, sys: 3.04 ms, total: 40.3 ms\n",
            "Wall time: 40.1 ms\n",
            "CPU times: user 35.1 ms, sys: 5.97 ms, total: 41.1 ms\n",
            "Wall time: 41 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS3f99lYbXDN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "93706623-21b2-412f-a58f-45ff9fa8da3b"
      },
      "source": [
        "text_list = []\n",
        "sentence_list = []\n",
        "word_list = []\n",
        "\n",
        "start = datetime.now()\n",
        "for i, sentence in tqdm(enumerate(transcript_df.transcript)):\n",
        "  for word in sentence.split():\n",
        "      sentence_list.append(f\"Sentence: {i}\")\n",
        "      if word.endswith(','):\n",
        "          word_list.append(word[:-1])\n",
        "          text_list.append(',')\n",
        "      elif word.endswith('.'):\n",
        "          word_list.append(word[:-1])\n",
        "          text_list.append('.')\n",
        "      elif word.endswith('?'):\n",
        "          word_list.append(word[:-1])\n",
        "          text_list.append('?')\n",
        "      elif word.endswith('!'):\n",
        "          word_list.append(word[:-1])\n",
        "          text_list.append('!')\n",
        "      else:\n",
        "          word_list.append(word)\n",
        "          text_list.append('O')\n",
        "\n",
        "print(f\"Time taken: {datetime.now() - start}\")\n",
        "data = pd.DataFrame({'Sentence #': sentence_list, 'Word': word_list, 'Tag': text_list})\n",
        "print(f\"Dataset shape: {data.shape}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2467it [00:06, 410.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken: 0:00:06.010795\n",
            "Dataset shape: (5086851, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "riOztP-8NXHT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ffe51ecb-e8ec-4246-d09b-1a59f4d38d62"
      },
      "source": [
        "print(\"Unique words in corpus:\", data['Word'].nunique())\n",
        "print(\"Unique tags in corpus:\", data['Tag'].nunique())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique words in corpus: 87371\n",
            "Unique tags in corpus: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYrgeuYHOxEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = list(set(data[\"Word\"].values))\n",
        "words.append(\"ENDPAD\")\n",
        "num_words = len(words)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQH6yutfOxEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tags = list(set(data[\"Tag\"].values))\n",
        "num_tags = len(tags)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M9D9JEzUbdnS"
      },
      "source": [
        "### Task 3: Retrieve Sentences and Corresponsing Tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VdJst_g5NYY_",
        "colab": {}
      },
      "source": [
        "class SentenceGetter(object):\n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                           s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nMUQLppspkPj",
        "colab": {}
      },
      "source": [
        "getter = SentenceGetter(data)\n",
        "sentences = getter.sentences"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GhiSTt2UdzYC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0ee5bdc0-528e-4203-fccd-957ecd777889"
      },
      "source": [
        "sentences[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Good', 'O'),\n",
              " ('morning', '.'),\n",
              " ('How', 'O'),\n",
              " ('are', 'O'),\n",
              " ('you', '?'),\n",
              " ('Its', 'O'),\n",
              " ('been', 'O'),\n",
              " ('great', ','),\n",
              " ('hasnt', 'O'),\n",
              " ('it', '?'),\n",
              " ('Ive', 'O'),\n",
              " ('been', 'O'),\n",
              " ('blown', 'O'),\n",
              " ('away', 'O'),\n",
              " ('by', 'O'),\n",
              " ('the', 'O'),\n",
              " ('whole', 'O'),\n",
              " ('thing', '.'),\n",
              " ('In', 'O'),\n",
              " ('fact', ','),\n",
              " ('Im', 'O'),\n",
              " ('leaving', '.'),\n",
              " ('There', 'O'),\n",
              " ('have', 'O'),\n",
              " ('been', 'O'),\n",
              " ('three', 'O'),\n",
              " ('themes', 'O'),\n",
              " ('running', 'O'),\n",
              " ('through', 'O'),\n",
              " ('the', 'O'),\n",
              " ('conference', 'O'),\n",
              " ('which', 'O'),\n",
              " ('are', 'O'),\n",
              " ('relevant', 'O'),\n",
              " ('to', 'O'),\n",
              " ('what', 'O'),\n",
              " ('I', 'O'),\n",
              " ('want', 'O'),\n",
              " ('to', 'O'),\n",
              " ('talk', 'O'),\n",
              " ('about', '.'),\n",
              " ('One', 'O'),\n",
              " ('is', 'O'),\n",
              " ('the', 'O'),\n",
              " ('extraordinary', 'O'),\n",
              " ('evidence', 'O'),\n",
              " ('of', 'O'),\n",
              " ('human', 'O'),\n",
              " ('creativity', 'O'),\n",
              " ('in', 'O'),\n",
              " ('all', 'O'),\n",
              " ('of', 'O'),\n",
              " ('the', 'O'),\n",
              " ('presentations', 'O'),\n",
              " ('that', 'O'),\n",
              " ('weve', 'O'),\n",
              " ('had', 'O'),\n",
              " ('and', 'O'),\n",
              " ('in', 'O'),\n",
              " ('all', 'O'),\n",
              " ('of', 'O'),\n",
              " ('the', 'O'),\n",
              " ('people', 'O'),\n",
              " ('here', '.'),\n",
              " ('Just', 'O'),\n",
              " ('the', 'O'),\n",
              " ('variety', 'O'),\n",
              " ('of', 'O'),\n",
              " ('it', 'O'),\n",
              " ('and', 'O'),\n",
              " ('the', 'O'),\n",
              " ('range', 'O'),\n",
              " ('of', 'O'),\n",
              " ('it', '.'),\n",
              " ('The', 'O'),\n",
              " ('second', 'O'),\n",
              " ('is', 'O'),\n",
              " ('that', 'O'),\n",
              " ('its', 'O'),\n",
              " ('put', 'O'),\n",
              " ('us', 'O'),\n",
              " ('in', 'O'),\n",
              " ('a', 'O'),\n",
              " ('place', 'O'),\n",
              " ('where', 'O'),\n",
              " ('we', 'O'),\n",
              " ('have', 'O'),\n",
              " ('no', 'O'),\n",
              " ('idea', 'O'),\n",
              " ('whats', 'O'),\n",
              " ('going', 'O'),\n",
              " ('to', 'O'),\n",
              " ('happen', ','),\n",
              " ('in', 'O'),\n",
              " ('terms', 'O'),\n",
              " ('of', 'O'),\n",
              " ('the', 'O'),\n",
              " ('future', '.'),\n",
              " ('No', 'O'),\n",
              " ('idea', 'O'),\n",
              " ('how', 'O'),\n",
              " ('this', 'O'),\n",
              " ('may', 'O'),\n",
              " ('play', 'O'),\n",
              " ('out', '.'),\n",
              " ('I', 'O'),\n",
              " ('have', 'O'),\n",
              " ('an', 'O'),\n",
              " ('interest', 'O'),\n",
              " ('in', 'O'),\n",
              " ('education', '.'),\n",
              " ('Actually', ','),\n",
              " ('what', 'O'),\n",
              " ('I', 'O'),\n",
              " ('find', 'O'),\n",
              " ('is', 'O'),\n",
              " ('everybody', 'O'),\n",
              " ('has', 'O'),\n",
              " ('an', 'O'),\n",
              " ('interest', 'O'),\n",
              " ('in', 'O'),\n",
              " ('education', '.'),\n",
              " ('Dont', 'O'),\n",
              " ('you', '?'),\n",
              " ('I', 'O'),\n",
              " ('find', 'O'),\n",
              " ('this', 'O'),\n",
              " ('very', 'O'),\n",
              " ('interesting', '.'),\n",
              " ('If', 'O'),\n",
              " ('youre', 'O'),\n",
              " ('at', 'O'),\n",
              " ('a', 'O'),\n",
              " ('dinner', 'O'),\n",
              " ('party', ','),\n",
              " ('and', 'O'),\n",
              " ('you', 'O'),\n",
              " ('say', 'O'),\n",
              " ('you', 'O'),\n",
              " ('work', 'O'),\n",
              " ('in', 'O'),\n",
              " ('education', 'O'),\n",
              " ('â€”', 'O'),\n",
              " ('Actually', ','),\n",
              " ('youre', 'O'),\n",
              " ('not', 'O'),\n",
              " ('often', 'O'),\n",
              " ('at', 'O'),\n",
              " ('dinner', 'O'),\n",
              " ('parties', ','),\n",
              " ('frankly', '.'),\n",
              " ('If', 'O'),\n",
              " ('you', 'O'),\n",
              " ('work', 'O'),\n",
              " ('in', 'O'),\n",
              " ('education', ','),\n",
              " ('youre', 'O'),\n",
              " ('not', 'O'),\n",
              " ('asked', '.'),\n",
              " ('And', 'O'),\n",
              " ('youre', 'O'),\n",
              " ('never', 'O'),\n",
              " ('asked', 'O'),\n",
              " ('back', ','),\n",
              " ('curiously', '.'),\n",
              " ('Thats', 'O'),\n",
              " ('strange', 'O'),\n",
              " ('to', 'O'),\n",
              " ('me', '.'),\n",
              " ('But', 'O'),\n",
              " ('if', 'O'),\n",
              " ('you', 'O'),\n",
              " ('are', ','),\n",
              " ('and', 'O'),\n",
              " ('you', 'O'),\n",
              " ('say', 'O'),\n",
              " ('to', 'O'),\n",
              " ('somebody', ','),\n",
              " ('you', 'O'),\n",
              " ('know', ','),\n",
              " ('they', 'O'),\n",
              " ('say', ','),\n",
              " ('What', 'O'),\n",
              " ('do', 'O'),\n",
              " ('you', 'O'),\n",
              " ('do', '?'),\n",
              " ('and', 'O'),\n",
              " ('you', 'O'),\n",
              " ('say', 'O'),\n",
              " ('you', 'O'),\n",
              " ('work', 'O'),\n",
              " ('in', 'O'),\n",
              " ('education', ','),\n",
              " ('you', 'O'),\n",
              " ('can', 'O'),\n",
              " ('see', 'O'),\n",
              " ('the', 'O'),\n",
              " ('blood', 'O'),\n",
              " ('run', 'O'),\n",
              " ('from', 'O'),\n",
              " ('their', 'O'),\n",
              " ('face', '.'),\n",
              " ('Theyre', 'O'),\n",
              " ('like', ','),\n",
              " ('Oh', 'O'),\n",
              " ('my', 'O'),\n",
              " ('God', ','),\n",
              " ('you', 'O'),\n",
              " ('know', ','),\n",
              " ('Why', 'O'),\n",
              " ('me', '?'),\n",
              " ('My', 'O'),\n",
              " ('one', 'O'),\n",
              " ('night', 'O'),\n",
              " ('out', 'O'),\n",
              " ('all', 'O'),\n",
              " ('week', '.'),\n",
              " ('But', 'O'),\n",
              " ('if', 'O'),\n",
              " ('you', 'O'),\n",
              " ('ask', 'O'),\n",
              " ('about', 'O'),\n",
              " ('their', 'O'),\n",
              " ('education', ','),\n",
              " ('they', 'O'),\n",
              " ('pin', 'O'),\n",
              " ('you', 'O'),\n",
              " ('to', 'O'),\n",
              " ('the', 'O'),\n",
              " ('wall', '.'),\n",
              " ('Because', 'O'),\n",
              " ('its', 'O'),\n",
              " ('one', 'O'),\n",
              " ('of', 'O'),\n",
              " ('those', 'O'),\n",
              " ('things', 'O'),\n",
              " ('that', 'O'),\n",
              " ('goes', 'O'),\n",
              " ('deep', 'O'),\n",
              " ('with', 'O'),\n",
              " ('people', ','),\n",
              " ('am', 'O'),\n",
              " ('I', 'O'),\n",
              " ('right', '?'),\n",
              " ('Like', 'O'),\n",
              " ('religion', ','),\n",
              " ('and', 'O'),\n",
              " ('money', 'O'),\n",
              " ('and', 'O'),\n",
              " ('other', 'O'),\n",
              " ('things', '.'),\n",
              " ('So', 'O'),\n",
              " ('I', 'O'),\n",
              " ('have', 'O'),\n",
              " ('a', 'O'),\n",
              " ('big', 'O'),\n",
              " ('interest', 'O'),\n",
              " ('in', 'O'),\n",
              " ('education', ','),\n",
              " ('and', 'O'),\n",
              " ('I', 'O'),\n",
              " ('think', 'O'),\n",
              " ('we', 'O'),\n",
              " ('all', 'O'),\n",
              " ('do', '.'),\n",
              " ('We', 'O'),\n",
              " ('have', 'O'),\n",
              " ('a', 'O'),\n",
              " ('huge', 'O'),\n",
              " ('vested', 'O'),\n",
              " ('interest', 'O'),\n",
              " ('in', 'O'),\n",
              " ('it', ','),\n",
              " ('partly', 'O'),\n",
              " ('because', 'O'),\n",
              " ('its', 'O'),\n",
              " ('education', 'O'),\n",
              " ('thats', 'O'),\n",
              " ('meant', 'O'),\n",
              " ('to', 'O'),\n",
              " ('take', 'O'),\n",
              " ('us', 'O'),\n",
              " ('into', 'O'),\n",
              " ('this', 'O'),\n",
              " ('future', 'O'),\n",
              " ('that', 'O'),\n",
              " ('we', 'O'),\n",
              " ('cant', 'O'),\n",
              " ('grasp', '.'),\n",
              " ('If', 'O'),\n",
              " ('you', 'O'),\n",
              " ('think', 'O'),\n",
              " ('of', 'O'),\n",
              " ('it', ','),\n",
              " ('children', 'O'),\n",
              " ('starting', 'O'),\n",
              " ('school', 'O'),\n",
              " ('this', 'O'),\n",
              " ('year', 'O'),\n",
              " ('will', 'O'),\n",
              " ('be', 'O'),\n",
              " ('retiring', 'O'),\n",
              " ('in', 'O'),\n",
              " ('2065', '.'),\n",
              " ('Nobody', 'O'),\n",
              " ('has', 'O'),\n",
              " ('a', 'O'),\n",
              " ('clue', ','),\n",
              " ('despite', 'O'),\n",
              " ('all', 'O'),\n",
              " ('the', 'O'),\n",
              " ('expertise', 'O'),\n",
              " ('thats', 'O'),\n",
              " ('been', 'O'),\n",
              " ('on', 'O'),\n",
              " ('parade', 'O'),\n",
              " ('for', 'O'),\n",
              " ('the', 'O'),\n",
              " ('past', 'O'),\n",
              " ('four', 'O'),\n",
              " ('days', ','),\n",
              " ('what', 'O'),\n",
              " ('the', 'O'),\n",
              " ('world', 'O'),\n",
              " ('will', 'O'),\n",
              " ('look', 'O'),\n",
              " ('like', 'O'),\n",
              " ('in', 'O'),\n",
              " ('five', 'O'),\n",
              " ('years', 'O'),\n",
              " ('time', '.'),\n",
              " ('And', 'O'),\n",
              " ('yet', 'O'),\n",
              " ('were', 'O'),\n",
              " ('meant', 'O'),\n",
              " ('to', 'O'),\n",
              " ('be', 'O'),\n",
              " ('educating', 'O'),\n",
              " ('them', 'O'),\n",
              " ('for', 'O'),\n",
              " ('it', '.'),\n",
              " ('So', 'O'),\n",
              " ('the', 'O'),\n",
              " ('unpredictability', ','),\n",
              " ('I', 'O'),\n",
              " ('think', ','),\n",
              " ('is', 'O'),\n",
              " ('extraordinary', '.'),\n",
              " ('And', 'O'),\n",
              " ('the', 'O'),\n",
              " ('third', 'O'),\n",
              " ('part', 'O'),\n",
              " ('of', 'O'),\n",
              " ('this', 'O'),\n",
              " ('is', 'O'),\n",
              " ('that', 'O'),\n",
              " ('weve', 'O'),\n",
              " ('all', 'O'),\n",
              " ('agreed', ','),\n",
              " ('nonetheless', ','),\n",
              " ('on', 'O'),\n",
              " ('the', 'O'),\n",
              " ('really', 'O'),\n",
              " ('extraordinary', 'O'),\n",
              " ('capacities', 'O'),\n",
              " ('that', 'O'),\n",
              " ('children', 'O'),\n",
              " ('have', 'O'),\n",
              " ('â€”', 'O'),\n",
              " ('their', 'O'),\n",
              " ('capacities', 'O'),\n",
              " ('for', 'O'),\n",
              " ('innovation', '.'),\n",
              " ('I', 'O'),\n",
              " ('mean', ','),\n",
              " ('Sirena', 'O'),\n",
              " ('last', 'O'),\n",
              " ('night', 'O'),\n",
              " ('was', 'O'),\n",
              " ('a', 'O'),\n",
              " ('marvel', ','),\n",
              " ('wasnt', 'O'),\n",
              " ('she', '?'),\n",
              " ('Just', 'O'),\n",
              " ('seeing', 'O'),\n",
              " ('what', 'O'),\n",
              " ('she', 'O'),\n",
              " ('could', 'O'),\n",
              " ('do', '.'),\n",
              " ('And', 'O'),\n",
              " ('shes', 'O'),\n",
              " ('exceptional', ','),\n",
              " ('but', 'O'),\n",
              " ('I', 'O'),\n",
              " ('think', 'O'),\n",
              " ('shes', 'O'),\n",
              " ('not', ','),\n",
              " ('so', 'O'),\n",
              " ('to', 'O'),\n",
              " ('speak', ','),\n",
              " ('exceptional', 'O'),\n",
              " ('in', 'O'),\n",
              " ('the', 'O'),\n",
              " ('whole', 'O'),\n",
              " ('of', 'O'),\n",
              " ('childhood', '.'),\n",
              " ('What', 'O'),\n",
              " ('you', 'O'),\n",
              " ('have', 'O'),\n",
              " ('there', 'O'),\n",
              " ('is', 'O'),\n",
              " ('a', 'O'),\n",
              " ('person', 'O'),\n",
              " ('of', 'O'),\n",
              " ('extraordinary', 'O'),\n",
              " ('dedication', 'O'),\n",
              " ('who', 'O'),\n",
              " ('found', 'O'),\n",
              " ('a', 'O'),\n",
              " ('talent', '.'),\n",
              " ('And', 'O'),\n",
              " ('my', 'O'),\n",
              " ('contention', 'O'),\n",
              " ('is', ','),\n",
              " ('all', 'O'),\n",
              " ('kids', 'O'),\n",
              " ('have', 'O'),\n",
              " ('tremendous', 'O'),\n",
              " ('talents', '.'),\n",
              " ('And', 'O'),\n",
              " ('we', 'O'),\n",
              " ('squander', 'O'),\n",
              " ('them', ','),\n",
              " ('pretty', 'O'),\n",
              " ('ruthlessly', '.'),\n",
              " ('So', 'O'),\n",
              " ('I', 'O'),\n",
              " ('want', 'O'),\n",
              " ('to', 'O'),\n",
              " ('talk', 'O'),\n",
              " ('about', 'O'),\n",
              " ('education', 'O'),\n",
              " ('and', 'O'),\n",
              " ('I', 'O'),\n",
              " ('want', 'O'),\n",
              " ('to', 'O'),\n",
              " ('talk', 'O'),\n",
              " ('about', 'O'),\n",
              " ('creativity', '.'),\n",
              " ('My', 'O'),\n",
              " ('contention', 'O'),\n",
              " ('is', 'O'),\n",
              " ('that', 'O'),\n",
              " ('creativity', 'O'),\n",
              " ('now', 'O'),\n",
              " ('is', 'O'),\n",
              " ('as', 'O'),\n",
              " ('important', 'O'),\n",
              " ('in', 'O'),\n",
              " ('education', 'O'),\n",
              " ('as', 'O'),\n",
              " ('literacy', ','),\n",
              " ('and', 'O'),\n",
              " ('we', 'O'),\n",
              " ('should', 'O'),\n",
              " ('treat', 'O'),\n",
              " ('it', 'O'),\n",
              " ('with', 'O'),\n",
              " ('the', 'O'),\n",
              " ('same', 'O'),\n",
              " ('status', '.'),\n",
              " ('Thank', 'O'),\n",
              " ('you', '.'),\n",
              " ('That', 'O'),\n",
              " ('was', 'O'),\n",
              " ('it', ','),\n",
              " ('by', 'O'),\n",
              " ('the', 'O'),\n",
              " ('way', '.'),\n",
              " ('Thank', 'O'),\n",
              " ('you', 'O'),\n",
              " ('very', 'O'),\n",
              " ('much', '.'),\n",
              " ('So', ','),\n",
              " ('15', 'O'),\n",
              " ('minutes', 'O'),\n",
              " ('left', '.'),\n",
              " ('Well', ','),\n",
              " ('I', 'O'),\n",
              " ('was', 'O'),\n",
              " ('born', '.'),\n",
              " ('', '.'),\n",
              " ('', '.'),\n",
              " ('no', '.'),\n",
              " ('I', 'O'),\n",
              " ('heard', 'O'),\n",
              " ('a', 'O'),\n",
              " ('great', 'O'),\n",
              " ('story', 'O'),\n",
              " ('recently', 'O'),\n",
              " ('â€”', 'O'),\n",
              " ('I', 'O'),\n",
              " ('love', 'O'),\n",
              " ('telling', 'O'),\n",
              " ('it', 'O'),\n",
              " ('â€”', 'O'),\n",
              " ('of', 'O'),\n",
              " ('a', 'O'),\n",
              " ('little', 'O'),\n",
              " ('girl', 'O'),\n",
              " ('who', 'O'),\n",
              " ('was', 'O'),\n",
              " ('in', 'O'),\n",
              " ('a', 'O'),\n",
              " ('drawing', 'O'),\n",
              " ('lesson', '.'),\n",
              " ('She', 'O'),\n",
              " ('was', 'O'),\n",
              " ('six', ','),\n",
              " ('and', 'O'),\n",
              " ('she', 'O'),\n",
              " ('was', 'O'),\n",
              " ('at', 'O'),\n",
              " ('the', 'O'),\n",
              " ('back', ','),\n",
              " ('drawing', ','),\n",
              " ('and', 'O'),\n",
              " ('the', 'O'),\n",
              " ('teacher', 'O'),\n",
              " ('said', 'O'),\n",
              " ('this', 'O'),\n",
              " ('girl', 'O'),\n",
              " ('hardly', 'O'),\n",
              " ('ever', 'O'),\n",
              " ('paid', 'O'),\n",
              " ('attention', ','),\n",
              " ('and', 'O'),\n",
              " ('in', 'O'),\n",
              " ('this', 'O'),\n",
              " ('drawing', 'O'),\n",
              " ('lesson', ','),\n",
              " ('she', 'O'),\n",
              " ('did', '.'),\n",
              " ('The', 'O'),\n",
              " ('teacher', 'O'),\n",
              " ('was', 'O'),\n",
              " ('fascinated', '.'),\n",
              " ('She', 'O'),\n",
              " ('went', 'O'),\n",
              " ('over', 'O'),\n",
              " ('to', 'O'),\n",
              " ('her', ','),\n",
              " ('and', 'O'),\n",
              " ('she', 'O'),\n",
              " ('said', ','),\n",
              " ('What', 'O'),\n",
              " ('are', 'O'),\n",
              " ('you', 'O'),\n",
              " ('drawing', '?'),\n",
              " ('And', 'O'),\n",
              " ('the', 'O'),\n",
              " ('girl', 'O'),\n",
              " ('said', ','),\n",
              " ('Im', 'O'),\n",
              " ('drawing', 'O'),\n",
              " ('a', 'O'),\n",
              " ('picture', 'O'),\n",
              " ('of', 'O'),\n",
              " ('God', '.'),\n",
              " ('And', 'O'),\n",
              " ('the', 'O'),\n",
              " ('teacher', 'O'),\n",
              " ('said', ','),\n",
              " ('But', 'O'),\n",
              " ('nobody', 'O'),\n",
              " ('knows', 'O'),\n",
              " ('what', 'O'),\n",
              " ('God', 'O'),\n",
              " ('looks', 'O'),\n",
              " ('like', '.'),\n",
              " ('And', 'O'),\n",
              " ('the', 'O'),\n",
              " ('girl', 'O'),\n",
              " ('said', ','),\n",
              " ('They', 'O'),\n",
              " ('will', ','),\n",
              " ('in', 'O'),\n",
              " ('a', 'O'),\n",
              " ('minute', '.'),\n",
              " ('When', 'O'),\n",
              " ('my', 'O'),\n",
              " ('son', 'O'),\n",
              " ('was', 'O'),\n",
              " ('four', 'O'),\n",
              " ('in', 'O'),\n",
              " ('England', 'O'),\n",
              " ('â€”', 'O'),\n",
              " ('Actually', ','),\n",
              " ('he', 'O'),\n",
              " ('was', 'O'),\n",
              " ('four', 'O'),\n",
              " ('everywhere', ','),\n",
              " ('to', 'O'),\n",
              " ('be', 'O'),\n",
              " ('honest', '.'),\n",
              " ('If', 'O'),\n",
              " ('were', 'O'),\n",
              " ('being', 'O'),\n",
              " ('strict', 'O'),\n",
              " ('about', 'O'),\n",
              " ('it', ','),\n",
              " ('wherever', 'O'),\n",
              " ('he', 'O'),\n",
              " ('went', ','),\n",
              " ('he', 'O'),\n",
              " ('was', 'O'),\n",
              " ('four', 'O'),\n",
              " ('that', 'O'),\n",
              " ('year', '.'),\n",
              " ('He', 'O'),\n",
              " ('was', 'O'),\n",
              " ('in', 'O'),\n",
              " ('the', 'O'),\n",
              " ('Nativity', 'O'),\n",
              " ('play', '.'),\n",
              " ('Do', 'O'),\n",
              " ('you', 'O'),\n",
              " ('remember', 'O'),\n",
              " ('the', 'O'),\n",
              " ('story', '?'),\n",
              " ('No', ','),\n",
              " ('it', 'O'),\n",
              " ('was', 'O'),\n",
              " ('big', ','),\n",
              " ('it', 'O'),\n",
              " ('was', 'O'),\n",
              " ('a', 'O'),\n",
              " ('big', 'O'),\n",
              " ('story', '.'),\n",
              " ('Mel', 'O'),\n",
              " ('Gibson', 'O'),\n",
              " ('did', 'O'),\n",
              " ('the', 'O'),\n",
              " ('sequel', ','),\n",
              " ('you', 'O'),\n",
              " ('may', 'O'),\n",
              " ('have', 'O'),\n",
              " ('seen', 'O'),\n",
              " ('it', '.'),\n",
              " ('Nativity', 'O'),\n",
              " ('II', '.'),\n",
              " ('But', 'O'),\n",
              " ('James', 'O'),\n",
              " ('got', 'O'),\n",
              " ('the', 'O'),\n",
              " ('part', 'O'),\n",
              " ('of', 'O'),\n",
              " ('Joseph', ','),\n",
              " ('which', 'O'),\n",
              " ('we', 'O'),\n",
              " ('were', 'O'),\n",
              " ('thrilled', 'O'),\n",
              " ('about', '.'),\n",
              " ('We', 'O'),\n",
              " ('considered', 'O'),\n",
              " ('this', 'O'),\n",
              " ('to', 'O'),\n",
              " ('be', 'O'),\n",
              " ('one', 'O'),\n",
              " ('of', 'O'),\n",
              " ('the', 'O'),\n",
              " ('lead', 'O'),\n",
              " ('parts', '.'),\n",
              " ('We', 'O'),\n",
              " ('had', 'O'),\n",
              " ('the', 'O'),\n",
              " ('place', 'O'),\n",
              " ('crammed', 'O'),\n",
              " ('full', 'O'),\n",
              " ('of', 'O'),\n",
              " ('agents', 'O'),\n",
              " ('in', 'O'),\n",
              " ('T-shirts:', 'O'),\n",
              " ('James', 'O'),\n",
              " ('Robinson', 'O'),\n",
              " ('IS', 'O'),\n",
              " ('Joseph', '!'),\n",
              " ('He', 'O'),\n",
              " ('didnt', 'O'),\n",
              " ('have', 'O'),\n",
              " ('to', 'O'),\n",
              " ('speak', ','),\n",
              " ('but', 'O'),\n",
              " ('you', 'O'),\n",
              " ('know', 'O'),\n",
              " ('the', 'O'),\n",
              " ('bit', 'O'),\n",
              " ('where', 'O'),\n",
              " ('the', 'O'),\n",
              " ('three', 'O'),\n",
              " ('kings', 'O'),\n",
              " ('come', 'O'),\n",
              " ('in', '?'),\n",
              " ('They', 'O'),\n",
              " ('come', 'O'),\n",
              " ('in', 'O'),\n",
              " ('bearing', 'O'),\n",
              " ('gifts', ','),\n",
              " ('gold', ','),\n",
              " ('frankincense', 'O'),\n",
              " ('and', 'O'),\n",
              " ('myrrh', '.'),\n",
              " ('This', 'O'),\n",
              " ('really', 'O'),\n",
              " ('happened', '.'),\n",
              " ('We', 'O'),\n",
              " ('were', 'O'),\n",
              " ('sitting', 'O'),\n",
              " ('there', 'O'),\n",
              " ('and', 'O'),\n",
              " ('I', 'O'),\n",
              " ('think', 'O'),\n",
              " ('they', 'O'),\n",
              " ('just', 'O'),\n",
              " ('went', 'O'),\n",
              " ('out', 'O'),\n",
              " ('of', 'O'),\n",
              " ('sequence', ','),\n",
              " ('because', 'O'),\n",
              " ('we', 'O'),\n",
              " ('talked', 'O'),\n",
              " ('to', 'O'),\n",
              " ('the', 'O'),\n",
              " ('little', 'O'),\n",
              " ('boy', 'O'),\n",
              " ('afterward', 'O'),\n",
              " ('and', 'O'),\n",
              " ('we', 'O'),\n",
              " ('said', ','),\n",
              " ('You', 'O'),\n",
              " ('OK', 'O'),\n",
              " ('with', 'O'),\n",
              " ('that', '?'),\n",
              " ('And', 'O'),\n",
              " ('he', 'O'),\n",
              " ('said', ','),\n",
              " ('Yeah', ','),\n",
              " ('why', '?'),\n",
              " ('Was', 'O'),\n",
              " ('that', 'O'),\n",
              " ('wrong', '?'),\n",
              " ('They', 'O'),\n",
              " ('just', 'O'),\n",
              " ('switched', '.'),\n",
              " ('The', 'O'),\n",
              " ('three', 'O'),\n",
              " ('boys', 'O'),\n",
              " ('came', 'O'),\n",
              " ('in', ','),\n",
              " ('four-year-olds', 'O'),\n",
              " ('with', 'O'),\n",
              " ('tea', 'O'),\n",
              " ('towels', 'O'),\n",
              " ('on', 'O'),\n",
              " ('their', 'O'),\n",
              " ('heads', ','),\n",
              " ('and', 'O'),\n",
              " ('they', 'O'),\n",
              " ('put', 'O'),\n",
              " ('these', 'O'),\n",
              " ('boxes', 'O'),\n",
              " ('down', ','),\n",
              " ('and', 'O'),\n",
              " ('the', 'O'),\n",
              " ('first', 'O'),\n",
              " ('boy', 'O'),\n",
              " ('said', ','),\n",
              " ('I', 'O'),\n",
              " ('bring', 'O'),\n",
              " ('you', 'O'),\n",
              " ('gold', '.'),\n",
              " ('And', 'O'),\n",
              " ('the', 'O'),\n",
              " ('second', 'O'),\n",
              " ('boy', 'O'),\n",
              " ('said', ','),\n",
              " ('I', 'O'),\n",
              " ('bring', 'O'),\n",
              " ('you', 'O'),\n",
              " ('myrrh', '.'),\n",
              " ('And', 'O'),\n",
              " ('the', 'O'),\n",
              " ('third', 'O'),\n",
              " ('boy', 'O'),\n",
              " ('said', ','),\n",
              " ('Frank', 'O'),\n",
              " ('sent', 'O'),\n",
              " ('this', '.'),\n",
              " ('What', 'O'),\n",
              " ('these', 'O'),\n",
              " ('things', 'O'),\n",
              " ('have', 'O'),\n",
              " ('in', 'O'),\n",
              " ('common', 'O'),\n",
              " ('is', 'O'),\n",
              " ('that', 'O'),\n",
              " ('kids', 'O'),\n",
              " ('will', 'O'),\n",
              " ('take', 'O'),\n",
              " ('a', 'O'),\n",
              " ('chance', '.'),\n",
              " ('If', 'O'),\n",
              " ('they', 'O'),\n",
              " ('dont', 'O'),\n",
              " ('know', ','),\n",
              " ('theyll', 'O'),\n",
              " ('have', 'O'),\n",
              " ('a', 'O'),\n",
              " ('go', '.'),\n",
              " ('Am', 'O'),\n",
              " ('I', 'O'),\n",
              " ('right', '?'),\n",
              " ('Theyre', 'O'),\n",
              " ('not', 'O'),\n",
              " ('frightened', 'O'),\n",
              " ('of', 'O'),\n",
              " ('being', 'O'),\n",
              " ('wrong', '.'),\n",
              " ('I', 'O'),\n",
              " ('dont', 'O'),\n",
              " ('mean', 'O'),\n",
              " ('to', 'O'),\n",
              " ('say', 'O'),\n",
              " ('that', 'O'),\n",
              " ('being', 'O'),\n",
              " ('wrong', 'O'),\n",
              " ('is', 'O'),\n",
              " ('the', 'O'),\n",
              " ('same', 'O'),\n",
              " ('thing', 'O'),\n",
              " ('as', 'O'),\n",
              " ('being', 'O'),\n",
              " ('creative', '.'),\n",
              " ('What', 'O'),\n",
              " ('we', 'O'),\n",
              " ('do', 'O'),\n",
              " ('know', 'O'),\n",
              " ('is', ','),\n",
              " ('if', 'O'),\n",
              " ('youre', 'O'),\n",
              " ('not', 'O'),\n",
              " ('prepared', 'O'),\n",
              " ('to', 'O'),\n",
              " ('be', 'O'),\n",
              " ('wrong', ','),\n",
              " ('youll', 'O'),\n",
              " ('never', 'O'),\n",
              " ('come', 'O'),\n",
              " ('up', 'O'),\n",
              " ('with', 'O'),\n",
              " ('anything', 'O'),\n",
              " ('original', 'O'),\n",
              " ('â€”', 'O'),\n",
              " ('if', 'O'),\n",
              " ('youre', 'O'),\n",
              " ('not', 'O'),\n",
              " ('prepared', 'O'),\n",
              " ('to', 'O'),\n",
              " ('be', 'O'),\n",
              " ('wrong', '.'),\n",
              " ('And', 'O'),\n",
              " ('by', 'O'),\n",
              " ('the', 'O'),\n",
              " ('time', 'O'),\n",
              " ('they', 'O'),\n",
              " ('get', 'O'),\n",
              " ('to', 'O'),\n",
              " ('be', 'O'),\n",
              " ('adults', ','),\n",
              " ('most', 'O'),\n",
              " ('kids', 'O'),\n",
              " ('have', 'O'),\n",
              " ('lost', 'O'),\n",
              " ('that', 'O'),\n",
              " ('capacity', '.'),\n",
              " ('They', 'O'),\n",
              " ('have', 'O'),\n",
              " ('become', 'O'),\n",
              " ('frightened', 'O'),\n",
              " ('of', 'O'),\n",
              " ('being', 'O'),\n",
              " ('wrong', '.'),\n",
              " ('And', 'O'),\n",
              " ('we', 'O'),\n",
              " ('run', 'O'),\n",
              " ('our', 'O'),\n",
              " ('companies', 'O'),\n",
              " ('like', 'O'),\n",
              " ('this', '.'),\n",
              " ('We', 'O'),\n",
              " ('stigmatize', 'O'),\n",
              " ('mistakes', '.'),\n",
              " ('And', 'O'),\n",
              " ('were', 'O'),\n",
              " ('now', 'O'),\n",
              " ('running', 'O'),\n",
              " ('national', 'O'),\n",
              " ('education', 'O'),\n",
              " ('systems', 'O'),\n",
              " ('where', 'O'),\n",
              " ('mistakes', 'O'),\n",
              " ('are', 'O'),\n",
              " ('the', 'O'),\n",
              " ('worst', 'O'),\n",
              " ('thing', 'O'),\n",
              " ('you', 'O'),\n",
              " ('can', 'O'),\n",
              " ('make', '.'),\n",
              " ('And', 'O'),\n",
              " ('the', 'O'),\n",
              " ('result', 'O'),\n",
              " ('is', 'O'),\n",
              " ('that', 'O'),\n",
              " ('we', 'O'),\n",
              " ('are', 'O'),\n",
              " ('educating', 'O'),\n",
              " ('people', 'O'),\n",
              " ('out', 'O'),\n",
              " ('of', 'O'),\n",
              " ('their', 'O'),\n",
              " ('creative', 'O'),\n",
              " ('capacities', '.'),\n",
              " ('Picasso', 'O'),\n",
              " ('once', 'O'),\n",
              " ('said', 'O'),\n",
              " ('this', ','),\n",
              " ('he', 'O'),\n",
              " ('said', 'O'),\n",
              " ('that', 'O'),\n",
              " ('all', 'O'),\n",
              " ('children', 'O'),\n",
              " ('are', 'O'),\n",
              " ('born', 'O'),\n",
              " ('artists', '.'),\n",
              " ('The', 'O'),\n",
              " ('problem', 'O'),\n",
              " ('is', 'O'),\n",
              " ('to', 'O'),\n",
              " ('remain', 'O'),\n",
              " ('an', 'O'),\n",
              " ('artist', 'O'),\n",
              " ('as', 'O'),\n",
              " ('we', 'O'),\n",
              " ('grow', 'O'),\n",
              " ('up', '.'),\n",
              " ('I', 'O'),\n",
              " ('believe', 'O'),\n",
              " ('this', 'O'),\n",
              " ('passionately', ','),\n",
              " ('that', 'O'),\n",
              " ('we', 'O'),\n",
              " ('dont', 'O'),\n",
              " ('grow', 'O'),\n",
              " ('into', 'O'),\n",
              " ('creativity', ','),\n",
              " ('we', 'O'),\n",
              " ('grow', 'O'),\n",
              " ('out', 'O'),\n",
              " ('of', 'O'),\n",
              " ('it', '.'),\n",
              " ('Or', 'O'),\n",
              " ('rather', ','),\n",
              " ('we', 'O'),\n",
              " ('get', 'O'),\n",
              " ('educated', 'O'),\n",
              " ('out', 'O'),\n",
              " ('of', 'O'),\n",
              " ('it', '.'),\n",
              " ('So', 'O'),\n",
              " ('why', 'O'),\n",
              " ('is', 'O'),\n",
              " ('this', '?'),\n",
              " ('I', 'O'),\n",
              " ('lived', 'O'),\n",
              " ('in', 'O'),\n",
              " ('Stratford-on-Avon', 'O'),\n",
              " ('until', 'O'),\n",
              " ('about', 'O'),\n",
              " ('five', 'O'),\n",
              " ('years', 'O'),\n",
              " ('ago', '.'),\n",
              " ('In', 'O'),\n",
              " ('fact', ','),\n",
              " ('we', 'O'),\n",
              " ('moved', 'O'),\n",
              " ('from', 'O'),\n",
              " ('Stratford', 'O'),\n",
              " ('to', 'O'),\n",
              " ('Los', 'O'),\n",
              " ('Angeles', '.'),\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ldhuogX4eHE4"
      },
      "source": [
        "### Task 4: Define Mappings between Sentences and Tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SvENHO18pkaQ",
        "colab": {}
      },
      "source": [
        "word2idx = {w: i + 1 for i, w in enumerate(words)}\n",
        "tag2idx = {t: i for i, t in enumerate(tags)}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h8iS-O3OxEd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9aebca10-dd94-44bd-81b0-3915e848e722"
      },
      "source": [
        "word2idx"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 1,\n",
              " 'Medawar': 2,\n",
              " 'claustrophobic': 3,\n",
              " 'nano-size': 4,\n",
              " 'weirding': 5,\n",
              " 'micro-loan': 6,\n",
              " 'ultrasensitive': 7,\n",
              " '47-year-old': 8,\n",
              " 'whiskey;': 9,\n",
              " 'wow;': 10,\n",
              " 'Spittin': 11,\n",
              " 'AK-47': 12,\n",
              " 'silver-tongued': 13,\n",
              " 'RP7;': 14,\n",
              " 'brush-stroked': 15,\n",
              " 'promoting': 16,\n",
              " 'dramatization': 17,\n",
              " 'spaceships': 18,\n",
              " 'Bering': 19,\n",
              " 'winnerstheres': 20,\n",
              " '[there': 21,\n",
              " 'Semco': 22,\n",
              " 'crate': 23,\n",
              " 'Prius': 24,\n",
              " 'burglary': 25,\n",
              " 'FRAC': 26,\n",
              " 'SCHOOL][OLD': 27,\n",
              " 'Zimbabwe': 28,\n",
              " 'Rotonda': 29,\n",
              " 'annually': 30,\n",
              " 'averaging': 31,\n",
              " 'unbeknownst': 32,\n",
              " 'Unveiling': 33,\n",
              " 'paisa': 34,\n",
              " 'all-you-can-eat': 35,\n",
              " 'adequate': 36,\n",
              " 'agencys': 37,\n",
              " 'lengthwise': 38,\n",
              " 'life-affirming': 39,\n",
              " 'Inanimate': 40,\n",
              " 'nanobots': 41,\n",
              " 'Operator': 42,\n",
              " 'Burwell': 43,\n",
              " 'portrayals': 44,\n",
              " '[Danny': 45,\n",
              " 'Dunne': 46,\n",
              " 'eco-certification': 47,\n",
              " 'Herbert': 48,\n",
              " 'anticoagulation': 49,\n",
              " 'Cassia': 50,\n",
              " '2003': 51,\n",
              " 'Belgium': 52,\n",
              " 'FAA': 53,\n",
              " 'Belize': 54,\n",
              " 'probation': 55,\n",
              " 'Ghani': 56,\n",
              " 'donor-conceived': 57,\n",
              " 'seventh-grade': 58,\n",
              " 'bet': 59,\n",
              " 'soon': 60,\n",
              " 'basically': 61,\n",
              " 'metarhizium': 62,\n",
              " 'Mesa': 63,\n",
              " 'Reboxetine': 64,\n",
              " 'burials': 65,\n",
              " 'uterus': 66,\n",
              " 'sourpuss': 67,\n",
              " 'Story][GJA': 68,\n",
              " 'Pheidippides': 69,\n",
              " 'Philadelphia:': 70,\n",
              " 'refracted': 71,\n",
              " 'card-carrying': 72,\n",
              " 'bisphenol': 73,\n",
              " '2004': 74,\n",
              " 'Belarussian': 75,\n",
              " 'Liu': 76,\n",
              " 'factor]': 77,\n",
              " 'Westchester': 78,\n",
              " 'Incorrect': 79,\n",
              " 'rigor;': 80,\n",
              " 'Bleep': 81,\n",
              " 'Brazil;': 82,\n",
              " 'stag': 83,\n",
              " 'boondoggle': 84,\n",
              " 'speculated': 85,\n",
              " 'Shinseki': 86,\n",
              " 'lipid': 87,\n",
              " 'frontiers': 88,\n",
              " 'Narcissism': 89,\n",
              " 'shoelaces': 90,\n",
              " 'super-exciting': 91,\n",
              " '[Plato]': 92,\n",
              " 'eating': 93,\n",
              " 'Juarez:': 94,\n",
              " 'Devising': 95,\n",
              " 'Tabby': 96,\n",
              " 'Katie': 97,\n",
              " 'proportionately': 98,\n",
              " 'war-fighting': 99,\n",
              " 'obstetrical': 100,\n",
              " 'derives': 101,\n",
              " 'Richly': 102,\n",
              " 'LOrÃ©al': 103,\n",
              " 'buggy': 104,\n",
              " 'Grease': 105,\n",
              " '59-year-old': 106,\n",
              " 'Ansari': 107,\n",
              " '[have]': 108,\n",
              " 'declassify': 109,\n",
              " 'pap': 110,\n",
              " 'technology': 111,\n",
              " 'skintight': 112,\n",
              " 'Open-ended': 113,\n",
              " 'Advocacy': 114,\n",
              " 'evolution;': 115,\n",
              " 'sledge': 116,\n",
              " 'reacquainted': 117,\n",
              " 'appearance-based': 118,\n",
              " 'untold': 119,\n",
              " 'debugging': 120,\n",
              " 'Public-Private': 121,\n",
              " 'epaulettes;': 122,\n",
              " 'domain-specific': 123,\n",
              " 'self-cleaning': 124,\n",
              " 'Kahlo': 125,\n",
              " 'Biona': 126,\n",
              " 'DADDY': 127,\n",
              " 'evolvability': 128,\n",
              " 'arcs': 129,\n",
              " 'foods;': 130,\n",
              " 'enemy': 131,\n",
              " 'reasoning': 132,\n",
              " 'Aida': 133,\n",
              " 'Lindbergh': 134,\n",
              " 'conceptualized': 135,\n",
              " 'dramatic:': 136,\n",
              " 'Margot': 137,\n",
              " 'Idleness': 138,\n",
              " 'SÃ¡nchez': 139,\n",
              " 'almanac': 140,\n",
              " 'Bezos:': 141,\n",
              " 'myeloma': 142,\n",
              " 'morrow': 143,\n",
              " 'spurted': 144,\n",
              " 'flimsy': 145,\n",
              " 'colonialization': 146,\n",
              " 'ha': 147,\n",
              " 'Bridgeport': 148,\n",
              " 'Coleman': 149,\n",
              " 'disruptions': 150,\n",
              " 'Spaghetti': 151,\n",
              " 'printable': 152,\n",
              " 'paste': 153,\n",
              " 'non-expert': 154,\n",
              " 'ratty': 155,\n",
              " 'location-specific': 156,\n",
              " 'Caplin;': 157,\n",
              " 'under-exercising': 158,\n",
              " 'Telmon': 159,\n",
              " 'Historical': 160,\n",
              " 'Cows': 161,\n",
              " 'Worthingtons': 162,\n",
              " 'grey;': 163,\n",
              " 'linkbait': 164,\n",
              " 'design;': 165,\n",
              " 'atrophies': 166,\n",
              " 'termite': 167,\n",
              " 'Carrying': 168,\n",
              " 'readiness': 169,\n",
              " 'repeals': 170,\n",
              " 'plantations': 171,\n",
              " 'mobile-first': 172,\n",
              " 'Terribly': 173,\n",
              " 'Bronte': 174,\n",
              " 'euphoric': 175,\n",
              " 'disseminating': 176,\n",
              " 'picking': 177,\n",
              " 'Tables:': 178,\n",
              " '1656': 179,\n",
              " 'exoplanet': 180,\n",
              " 'more:': 181,\n",
              " 'nutritionists': 182,\n",
              " 'pollinators': 183,\n",
              " 'coconuts': 184,\n",
              " 'Foxx': 185,\n",
              " 'Broad': 186,\n",
              " 'Gunpowder': 187,\n",
              " 'uninflated': 188,\n",
              " 'repainting': 189,\n",
              " 'products:': 190,\n",
              " 'Elena': 191,\n",
              " 'kitchen': 192,\n",
              " 'founders': 193,\n",
              " 'grocery': 194,\n",
              " 'Malcolms': 195,\n",
              " 'fictional': 196,\n",
              " 'priesthood;': 197,\n",
              " 'Palestinian': 198,\n",
              " 'Longitude': 199,\n",
              " '5:': 200,\n",
              " 'hasJustineLandedYet': 201,\n",
              " 'riverside': 202,\n",
              " 'denominations': 203,\n",
              " 'JJ': 204,\n",
              " 'deejays': 205,\n",
              " 'mesh': 206,\n",
              " 'attenuate': 207,\n",
              " 'tainted': 208,\n",
              " 'Utrecht': 209,\n",
              " 'Macarena': 210,\n",
              " 'techno-crafted': 211,\n",
              " 'grange': 212,\n",
              " 'burning': 213,\n",
              " 'created:': 214,\n",
              " 'gyri': 215,\n",
              " 'once-thriving': 216,\n",
              " 'fleeting': 217,\n",
              " 'Beecher': 218,\n",
              " 'antigens': 219,\n",
              " 'Carta': 220,\n",
              " 'Union': 221,\n",
              " 'lint': 222,\n",
              " 'chaos': 223,\n",
              " 'halting': 224,\n",
              " 'navy': 225,\n",
              " 'Fez': 226,\n",
              " 'Ronald': 227,\n",
              " 'superorganism': 228,\n",
              " 'Pep': 229,\n",
              " 'subtractive': 230,\n",
              " 'Poochi': 231,\n",
              " 'Kahneman:': 232,\n",
              " 'generation:': 233,\n",
              " 'fattest': 234,\n",
              " 'Joshuas': 235,\n",
              " 'joyfulness': 236,\n",
              " 'diet-and-exercise': 237,\n",
              " 'EMC:': 238,\n",
              " 'teacher;': 239,\n",
              " 'bitten': 240,\n",
              " 'trigger': 241,\n",
              " 'bloodbath': 242,\n",
              " 'Revels': 243,\n",
              " 'hurly-burly': 244,\n",
              " 'hydrology': 245,\n",
              " 'Chimero': 246,\n",
              " 'Girgis': 247,\n",
              " '-certified': 248,\n",
              " 'neurochemicals': 249,\n",
              " 'Maison': 250,\n",
              " 'tomorrow': 251,\n",
              " 'BeyoncÃ©': 252,\n",
              " 'stratosphere:': 253,\n",
              " 'barefoot': 254,\n",
              " 'Lightning': 255,\n",
              " 'combed': 256,\n",
              " 'icons': 257,\n",
              " 'almonds': 258,\n",
              " 'taxes': 259,\n",
              " 'customizing': 260,\n",
              " 'interviews': 261,\n",
              " 'Amira': 262,\n",
              " 'sub-segment': 263,\n",
              " 'integrations': 264,\n",
              " 'zero-gravity': 265,\n",
              " 'Mitla': 266,\n",
              " 'Employees': 267,\n",
              " 'evacuate': 268,\n",
              " 'sexlessness': 269,\n",
              " 'Sienese': 270,\n",
              " 'Pei': 271,\n",
              " 'anew': 272,\n",
              " 'Christmas': 273,\n",
              " 'magicians': 274,\n",
              " 'motive:': 275,\n",
              " 'further;': 276,\n",
              " 'seniors': 277,\n",
              " 'horde': 278,\n",
              " 'Denisovans': 279,\n",
              " 'bud': 280,\n",
              " 'panoply': 281,\n",
              " 'reactivity': 282,\n",
              " 'Azuri': 283,\n",
              " 'discrimination': 284,\n",
              " 'inscription': 285,\n",
              " 'top-priority': 286,\n",
              " 'Achill': 287,\n",
              " 'wheelchairs': 288,\n",
              " 'only': 289,\n",
              " 'commercial': 290,\n",
              " 'Kyoto:': 291,\n",
              " 'skeptically': 292,\n",
              " 'magazines': 293,\n",
              " 'JC:': 294,\n",
              " 'aerobic': 295,\n",
              " 'stewardship': 296,\n",
              " 'rescale': 297,\n",
              " 'Iranian': 298,\n",
              " 'absorption': 299,\n",
              " 'Oates': 300,\n",
              " 'neoteny': 301,\n",
              " 'basement;': 302,\n",
              " 'lost:': 303,\n",
              " 'Al': 304,\n",
              " 'accomplished': 305,\n",
              " 'proscenium': 306,\n",
              " 'premiered': 307,\n",
              " 'vulnerabilites': 308,\n",
              " 'matched': 309,\n",
              " 'fought': 310,\n",
              " 'falling': 311,\n",
              " 'restructuring': 312,\n",
              " 'kinderhook': 313,\n",
              " 'Horns': 314,\n",
              " 'help': 315,\n",
              " 'Javan': 316,\n",
              " 'Local': 317,\n",
              " 'mutual-fund': 318,\n",
              " 'Nico': 319,\n",
              " 'half-century': 320,\n",
              " 'tradition-keepers': 321,\n",
              " 'purpose-built': 322,\n",
              " 'Brotherhood': 323,\n",
              " 'disembody': 324,\n",
              " 'biennials': 325,\n",
              " 'lettuces': 326,\n",
              " 'expanding:': 327,\n",
              " 'low-stakes': 328,\n",
              " 'non-stressful': 329,\n",
              " 'tolerance;': 330,\n",
              " 'meld': 331,\n",
              " 'Glad': 332,\n",
              " 'unsafest': 333,\n",
              " 'cost-benefits': 334,\n",
              " 'MAS:': 335,\n",
              " 'Sat': 336,\n",
              " 'hemisphere': 337,\n",
              " 'Darknet': 338,\n",
              " 'irresolution': 339,\n",
              " 'commune': 340,\n",
              " 'bombed': 341,\n",
              " 'us:': 342,\n",
              " 'agreeable': 343,\n",
              " 'crank': 344,\n",
              " '62': 345,\n",
              " 'Status-driven': 346,\n",
              " 'chickenosaurus': 347,\n",
              " 'extraordinarily': 348,\n",
              " 'mirabile': 349,\n",
              " 'Lickliders': 350,\n",
              " 'higher-income': 351,\n",
              " 'Judd:': 352,\n",
              " 'forget': 353,\n",
              " 'Philanthropy': 354,\n",
              " 'If-then': 355,\n",
              " 'transponders': 356,\n",
              " 'rear-wheel': 357,\n",
              " 'Civics': 358,\n",
              " 'alone': 359,\n",
              " 'reach;': 360,\n",
              " 'Uganda-Tanzania': 361,\n",
              " 'runways': 362,\n",
              " 'Thursdays': 363,\n",
              " 'weakening': 364,\n",
              " 'overlay': 365,\n",
              " 'tongkonan': 366,\n",
              " 'securities': 367,\n",
              " 'den': 368,\n",
              " 'seasons': 369,\n",
              " 'grandaddy': 370,\n",
              " 'foursquare': 371,\n",
              " 'pills;': 372,\n",
              " 'functionalism': 373,\n",
              " 'dinosuars': 374,\n",
              " 'pump;': 375,\n",
              " 'Revolutions': 376,\n",
              " 'Sonos': 377,\n",
              " 'manager': 378,\n",
              " 'Crop': 379,\n",
              " 'easing': 380,\n",
              " 'Romero:': 381,\n",
              " 'whiteboard': 382,\n",
              " 'mile': 383,\n",
              " 'Soleil': 384,\n",
              " 'long-tail': 385,\n",
              " 'safe': 386,\n",
              " 'beeswax': 387,\n",
              " 'expo': 388,\n",
              " 'secretive': 389,\n",
              " '15-month-old': 390,\n",
              " 'mouth-to-mouth': 391,\n",
              " 'Pauling': 392,\n",
              " 'arrests': 393,\n",
              " 'Charlotte': 394,\n",
              " 'cocaines': 395,\n",
              " 'pimp': 396,\n",
              " 'biologging': 397,\n",
              " 'FARC': 398,\n",
              " 'steel;': 399,\n",
              " 'lifestyle;': 400,\n",
              " 'peeves': 401,\n",
              " 'community-supported': 402,\n",
              " 'Emotional': 403,\n",
              " 'slackers': 404,\n",
              " 'Sports': 405,\n",
              " 'eye:': 406,\n",
              " 'quick-fix': 407,\n",
              " 'five-year-olds': 408,\n",
              " 'aka': 409,\n",
              " 'Raindrop': 410,\n",
              " 'dementing': 411,\n",
              " 'procrastinators': 412,\n",
              " 'sweats': 413,\n",
              " 'undoubted': 414,\n",
              " 'changemakers': 415,\n",
              " 'Interpol': 416,\n",
              " '250-piece': 417,\n",
              " 'Philo': 418,\n",
              " 'Stawis': 419,\n",
              " 'proposed': 420,\n",
              " 'rapport': 421,\n",
              " 'From': 422,\n",
              " 'Necessity': 423,\n",
              " 'petrol': 424,\n",
              " 'Trans-Pacific': 425,\n",
              " 'sprinkle': 426,\n",
              " 'calculations': 427,\n",
              " 'Blackberries': 428,\n",
              " 'libraries': 429,\n",
              " 'bale': 430,\n",
              " 'forum': 431,\n",
              " 'Godard': 432,\n",
              " 'wicker-basket': 433,\n",
              " 'flounder': 434,\n",
              " 'sucked-out': 435,\n",
              " 'nasality': 436,\n",
              " 'Rift': 437,\n",
              " 'head-tail-tail;': 438,\n",
              " 'qi': 439,\n",
              " 'abseil': 440,\n",
              " 'Moment]': 441,\n",
              " 'Microbiology': 442,\n",
              " 'Uncle': 443,\n",
              " 'Mastery:': 444,\n",
              " 'Gametrak': 445,\n",
              " 'Abzug': 446,\n",
              " 'okra': 447,\n",
              " 'Know-It-All': 448,\n",
              " 'Addams:': 449,\n",
              " 'DuPont': 450,\n",
              " 'advocating': 451,\n",
              " 'worsens': 452,\n",
              " 'ITER': 453,\n",
              " 'ex-boyfriends': 454,\n",
              " 'Transparency': 455,\n",
              " 'approachability': 456,\n",
              " 'attorneys': 457,\n",
              " 'highly': 458,\n",
              " 'HyDRASs': 459,\n",
              " 'idol': 460,\n",
              " 'acknowledges': 461,\n",
              " 'Sixty-three': 462,\n",
              " 'hidin': 463,\n",
              " 'Sometimes': 464,\n",
              " 'act': 465,\n",
              " 'WP:': 466,\n",
              " 'Sewards': 467,\n",
              " 'fixed-capacity': 468,\n",
              " 'Philiosophers': 469,\n",
              " 'Salutations': 470,\n",
              " 'Naela': 471,\n",
              " 'Improvement': 472,\n",
              " 'tendentious': 473,\n",
              " 'phenomenal': 474,\n",
              " 'Sixties': 475,\n",
              " 'widest-ranging': 476,\n",
              " 'summarily': 477,\n",
              " 'powering': 478,\n",
              " 'condemnatory': 479,\n",
              " 'resident': 480,\n",
              " 'tower': 481,\n",
              " 'mots': 482,\n",
              " 'Holladay:': 483,\n",
              " 'slathered': 484,\n",
              " 'Softly': 485,\n",
              " 'homosexuals': 486,\n",
              " 'space-based': 487,\n",
              " 'Discouraging': 488,\n",
              " 'compassionate': 489,\n",
              " 'Rush': 490,\n",
              " 'rivet-less': 491,\n",
              " 'vampire': 492,\n",
              " 'ELAM': 493,\n",
              " 'four-lane': 494,\n",
              " 'third-story': 495,\n",
              " 'itch': 496,\n",
              " 'healthcare': 497,\n",
              " 'Governments;': 498,\n",
              " 'communion': 499,\n",
              " 'TCP/IP': 500,\n",
              " 'dislocation': 501,\n",
              " 'cloning': 502,\n",
              " 'Aksum': 503,\n",
              " 'patenting': 504,\n",
              " '1928': 505,\n",
              " 'daze': 506,\n",
              " 'teaspoons': 507,\n",
              " 'Ramayana': 508,\n",
              " 'Hale-Bopp': 509,\n",
              " 'pork;': 510,\n",
              " 'tutoring': 511,\n",
              " 'unpredictability': 512,\n",
              " 'Stem': 513,\n",
              " 'PLoS': 514,\n",
              " 'homeopathy': 515,\n",
              " 'pick-and-rolls': 516,\n",
              " 'fÃ¼r': 517,\n",
              " 'applying': 518,\n",
              " 'adhering': 519,\n",
              " 'glass-stained': 520,\n",
              " 'backpedal': 521,\n",
              " 'flapper': 522,\n",
              " 'Braun': 523,\n",
              " 'Bolinsky': 524,\n",
              " 'persuasions': 525,\n",
              " 'stuck-key': 526,\n",
              " 'meWhen': 527,\n",
              " 'Lizard': 528,\n",
              " 'shanty': 529,\n",
              " 'introduced': 530,\n",
              " 'picture': 531,\n",
              " 'vets:': 532,\n",
              " 'FrisÃ©n': 533,\n",
              " 'stuntmen': 534,\n",
              " 'half-destroyed': 535,\n",
              " 'acronym:': 536,\n",
              " 'Entering': 537,\n",
              " 'antiquus': 538,\n",
              " ']And': 539,\n",
              " 'coronary': 540,\n",
              " 'edifies': 541,\n",
              " 'UTI': 542,\n",
              " 'wIye': 543,\n",
              " 'Miasmas': 544,\n",
              " 'mistreat': 545,\n",
              " 'innovations:': 546,\n",
              " 'seeding': 547,\n",
              " 'microbiology': 548,\n",
              " 'unremarkable': 549,\n",
              " 'terraced': 550,\n",
              " 'Museum': 551,\n",
              " 'plummeting': 552,\n",
              " 'noodling': 553,\n",
              " 'Chinese-American': 554,\n",
              " 'instilling': 555,\n",
              " 'Unhappily': 556,\n",
              " 'earlier:': 557,\n",
              " 'Seinfeld': 558,\n",
              " 'stain-resistant': 559,\n",
              " 'Airbnbs': 560,\n",
              " 'KPIs': 561,\n",
              " 'Association': 562,\n",
              " '$40': 563,\n",
              " 'vernal': 564,\n",
              " 'prefix': 565,\n",
              " 'accidental;': 566,\n",
              " 'makeup': 567,\n",
              " 'pollution-free': 568,\n",
              " 'unambiguous': 569,\n",
              " 'fiendishly': 570,\n",
              " 'render': 571,\n",
              " 'stutter': 572,\n",
              " 'defying': 573,\n",
              " 'genomic': 574,\n",
              " 'brands': 575,\n",
              " 'time-starved': 576,\n",
              " 'alluding': 577,\n",
              " 'wolves': 578,\n",
              " 'monodrama': 579,\n",
              " 'Tortugas': 580,\n",
              " 'Shimmer': 581,\n",
              " 'intl': 582,\n",
              " 'Urals': 583,\n",
              " 'air-conditioning;': 584,\n",
              " 'superblocks': 585,\n",
              " 'information;': 586,\n",
              " 'Arndt': 587,\n",
              " 'Wolmetz:': 588,\n",
              " 'uncouth;': 589,\n",
              " '200-feet-tall': 590,\n",
              " 'dramatists': 591,\n",
              " 'results-focus': 592,\n",
              " 'Mother:': 593,\n",
              " 'admire': 594,\n",
              " 'massacred': 595,\n",
              " 'anti-propaganda': 596,\n",
              " 'timestamped': 597,\n",
              " 'pollinate': 598,\n",
              " 'McCracken': 599,\n",
              " 'rollerblade': 600,\n",
              " 'nevertheless': 601,\n",
              " 'electrons': 602,\n",
              " 'explosions': 603,\n",
              " 'COM': 604,\n",
              " 'carves': 605,\n",
              " 'giving:': 606,\n",
              " 'Consumerism': 607,\n",
              " 'Dormouse': 608,\n",
              " 'poppers': 609,\n",
              " 'over-excitable': 610,\n",
              " 'dragonfly': 611,\n",
              " 'Adichie:': 612,\n",
              " 'Hoelzel': 613,\n",
              " 'isolating': 614,\n",
              " 'quotes': 615,\n",
              " 'potluck': 616,\n",
              " 'cumulative': 617,\n",
              " 'Bushehr': 618,\n",
              " 'biosensor': 619,\n",
              " 'pie-in-the-sky': 620,\n",
              " 'Nile': 621,\n",
              " 'marche': 622,\n",
              " 'fractures': 623,\n",
              " 'reel-to-reel': 624,\n",
              " 'glow': 625,\n",
              " 'collector': 626,\n",
              " 'otter': 627,\n",
              " 'conquered': 628,\n",
              " 'rafting': 629,\n",
              " 'sesame': 630,\n",
              " 'consistency': 631,\n",
              " 'hard-wearing': 632,\n",
              " 'extravagance': 633,\n",
              " 'Surrounded': 634,\n",
              " 'â€”DT:': 635,\n",
              " 'â€”in': 636,\n",
              " 'Soldier:': 637,\n",
              " 'Sheâ€™s': 638,\n",
              " 'Absurd': 639,\n",
              " 'diluting': 640,\n",
              " 'ovens': 641,\n",
              " 'Human-forced': 642,\n",
              " 'wickets': 643,\n",
              " 'grazing': 644,\n",
              " 'evacuating': 645,\n",
              " 'Institution': 646,\n",
              " 'paddling': 647,\n",
              " 'succumbs': 648,\n",
              " 'aimless': 649,\n",
              " 'penis]': 650,\n",
              " 'Ã‰puise': 651,\n",
              " '[Uphill': 652,\n",
              " 'tricks': 653,\n",
              " 'millefiori': 654,\n",
              " 'unsubstantiated': 655,\n",
              " 'Farmer]': 656,\n",
              " 'Thrun': 657,\n",
              " 'weakens': 658,\n",
              " 'painting:': 659,\n",
              " 'L2': 660,\n",
              " 'infallibly': 661,\n",
              " 'tinctures': 662,\n",
              " 'Albuquerque': 663,\n",
              " 'Emerging': 664,\n",
              " 'three-by-three': 665,\n",
              " 'Poll': 666,\n",
              " 'Fatality': 667,\n",
              " 'trompe': 668,\n",
              " 'megabytes': 669,\n",
              " 'deescalate': 670,\n",
              " 'Nations': 671,\n",
              " 'Andre': 672,\n",
              " 'car-ownership': 673,\n",
              " 'Nepal;': 674,\n",
              " 'Marmite': 675,\n",
              " 'Platonist': 676,\n",
              " 'fire': 677,\n",
              " 'Shikari': 678,\n",
              " '1960': 679,\n",
              " 'Anyhow': 680,\n",
              " 'Washingtons': 681,\n",
              " 'breakup': 682,\n",
              " 'conductors': 683,\n",
              " 'Allowance': 684,\n",
              " 'mice': 685,\n",
              " 'grid': 686,\n",
              " 'Time': 687,\n",
              " 'OCD': 688,\n",
              " 'Swann': 689,\n",
              " 'psych': 690,\n",
              " 'drive-through': 691,\n",
              " 'achingly': 692,\n",
              " 'truer': 693,\n",
              " 'Psychotic': 694,\n",
              " 'was]': 695,\n",
              " 'Greenpeaces': 696,\n",
              " 'embankment': 697,\n",
              " 'cupola': 698,\n",
              " 'sleeve': 699,\n",
              " 'Thunderwear': 700,\n",
              " 'defeating': 701,\n",
              " 'catalogue': 702,\n",
              " 'reminiscing': 703,\n",
              " 'attributable': 704,\n",
              " 'ASDFASDF': 705,\n",
              " 'Go:': 706,\n",
              " 'lower-middle-income': 707,\n",
              " 'devoured': 708,\n",
              " 'buckshot': 709,\n",
              " 'coin-flip': 710,\n",
              " 'Banner': 711,\n",
              " '250': 712,\n",
              " 'Opossum': 713,\n",
              " 'strong': 714,\n",
              " 'Civic': 715,\n",
              " 'Kene': 716,\n",
              " 'dialed': 717,\n",
              " 'glaciated': 718,\n",
              " 'WF:': 719,\n",
              " 'SPF': 720,\n",
              " 'Foreplay': 721,\n",
              " 'Wha': 722,\n",
              " 'disputes': 723,\n",
              " 'rocky': 724,\n",
              " 'Futures': 725,\n",
              " 'Stupidity': 726,\n",
              " 'MarÃ­a': 727,\n",
              " 'quivering': 728,\n",
              " 'connectional': 729,\n",
              " 'Cremation': 730,\n",
              " 'contrapoder': 731,\n",
              " 'Martha': 732,\n",
              " 'Bench': 733,\n",
              " 'choice': 734,\n",
              " 'Corruption': 735,\n",
              " 'emotion-enabling': 736,\n",
              " 'butchered': 737,\n",
              " 'symmetric': 738,\n",
              " 'open-air': 739,\n",
              " 'pictographs': 740,\n",
              " 'porous': 741,\n",
              " 'lattice-type': 742,\n",
              " 'Idol': 743,\n",
              " 'preprogram': 744,\n",
              " 'Bed-Stuy': 745,\n",
              " 'Carwash': 746,\n",
              " 'LG': 747,\n",
              " 'Infowars': 748,\n",
              " 'involved': 749,\n",
              " 'involuntary': 750,\n",
              " 'emcee': 751,\n",
              " 'descended': 752,\n",
              " 'certificate': 753,\n",
              " 'Khajuraho': 754,\n",
              " 'Indiana': 755,\n",
              " 'pincushions': 756,\n",
              " 'bluetooth': 757,\n",
              " 'ownIâ€™m': 758,\n",
              " 'mesosphere': 759,\n",
              " 'endowment': 760,\n",
              " 'reasoners': 761,\n",
              " 'gatehouse': 762,\n",
              " 'deadly': 763,\n",
              " 'gay-colored': 764,\n",
              " 'overshadowed': 765,\n",
              " 'articulately': 766,\n",
              " 'Method': 767,\n",
              " 'Fiore': 768,\n",
              " 'caprylic': 769,\n",
              " 'high-abundant': 770,\n",
              " 'Struggle': 771,\n",
              " 'neurodevelopment': 772,\n",
              " 'mantas': 773,\n",
              " 'Pantheon': 774,\n",
              " 'pre-processed': 775,\n",
              " 'pollinates': 776,\n",
              " 'colleagues': 777,\n",
              " 'calms': 778,\n",
              " 'Baja': 779,\n",
              " 'cell-phone': 780,\n",
              " 'near-miss': 781,\n",
              " 'Gorgonopsian': 782,\n",
              " 'cost': 783,\n",
              " 'irrationalisms': 784,\n",
              " 'astray': 785,\n",
              " 'TerraPower': 786,\n",
              " 'empowered': 787,\n",
              " 'gearing': 788,\n",
              " 'Hockey': 789,\n",
              " 'Mohsin': 790,\n",
              " 'lensing': 791,\n",
              " 'elementary-level': 792,\n",
              " 'overrun': 793,\n",
              " '[rocking': 794,\n",
              " 'sound:': 795,\n",
              " 'stealing': 796,\n",
              " 'recopying': 797,\n",
              " 'aid': 798,\n",
              " 'developing][36': 799,\n",
              " 'Owings': 800,\n",
              " 'intuition:': 801,\n",
              " 'Clinton:': 802,\n",
              " 'swellable': 803,\n",
              " 'Ahmad': 804,\n",
              " 'well-off': 805,\n",
              " 'Severnaya': 806,\n",
              " 'glitters': 807,\n",
              " 'refuses': 808,\n",
              " 're-crafted': 809,\n",
              " 'Puzzles': 810,\n",
              " 'update': 811,\n",
              " 'certainties': 812,\n",
              " 'triad': 813,\n",
              " 'unfortunate': 814,\n",
              " 'grasslands': 815,\n",
              " 'foreknowledge': 816,\n",
              " 'solar': 817,\n",
              " 'meltdown': 818,\n",
              " 'eater': 819,\n",
              " 'melancholy': 820,\n",
              " 'receiver': 821,\n",
              " 'X-light': 822,\n",
              " 'gutted': 823,\n",
              " 'Ryder': 824,\n",
              " 'Ebola': 825,\n",
              " 'narration': 826,\n",
              " 'body-love': 827,\n",
              " 'Chapman': 828,\n",
              " 'reception': 829,\n",
              " 'Wii': 830,\n",
              " 'premiers': 831,\n",
              " 'mid-1960s': 832,\n",
              " 'McCoy': 833,\n",
              " 'â€”again': 834,\n",
              " 'disguise': 835,\n",
              " 'Hungary;': 836,\n",
              " 'prosopagnosia': 837,\n",
              " 'Yeats': 838,\n",
              " 'allele': 839,\n",
              " 'Jurassic': 840,\n",
              " 'schlocky': 841,\n",
              " 'doled': 842,\n",
              " 'undulating': 843,\n",
              " 'diligently': 844,\n",
              " 'slime-producing': 845,\n",
              " 'pulls': 846,\n",
              " 'resemble': 847,\n",
              " 'Stuart:': 848,\n",
              " 'daughters': 849,\n",
              " 'Corporation': 850,\n",
              " 'One-piece': 851,\n",
              " 'Props': 852,\n",
              " 'priceless': 853,\n",
              " 'Zacchini': 854,\n",
              " 'iPad': 855,\n",
              " 'apologetic': 856,\n",
              " 'ins': 857,\n",
              " 'struggle;': 858,\n",
              " 'adhere': 859,\n",
              " 'mystique': 860,\n",
              " 'fears': 861,\n",
              " 'wheat': 862,\n",
              " 'aAudience:': 863,\n",
              " 'Krishnan': 864,\n",
              " 'immunogenicity': 865,\n",
              " 'hums': 866,\n",
              " 'trifecta': 867,\n",
              " 'anyplace': 868,\n",
              " '473': 869,\n",
              " 'adapting': 870,\n",
              " '50th': 871,\n",
              " 'inspired-by-nature': 872,\n",
              " 'Bonobos': 873,\n",
              " 'tapper': 874,\n",
              " 'orthodox': 875,\n",
              " 'Wrap': 876,\n",
              " 'myocytes': 877,\n",
              " 'Macedon': 878,\n",
              " 'symbols': 879,\n",
              " 'BRCK': 880,\n",
              " 'man-made': 881,\n",
              " 'Paine': 882,\n",
              " 'cycle-based': 883,\n",
              " 'accordion-folded': 884,\n",
              " 'mam': 885,\n",
              " 'EMT': 886,\n",
              " 'rapidity': 887,\n",
              " 'braves': 888,\n",
              " 'droplets': 889,\n",
              " 'Pebble': 890,\n",
              " 're-offending': 891,\n",
              " 'fierce': 892,\n",
              " 'U': 893,\n",
              " 'Term': 894,\n",
              " 'multi-religious': 895,\n",
              " 'Composition': 896,\n",
              " 'stated': 897,\n",
              " 'drowned': 898,\n",
              " 'Haleakala': 899,\n",
              " 'Snapchatters': 900,\n",
              " 'Escher-like': 901,\n",
              " 'weapons;': 902,\n",
              " 'outlined': 903,\n",
              " 'pedestal': 904,\n",
              " 'SCVNGR': 905,\n",
              " 'Creators': 906,\n",
              " 'product;': 907,\n",
              " 'prose': 908,\n",
              " 'dinnertime': 909,\n",
              " 'Endangered': 910,\n",
              " 'Churches': 911,\n",
              " 'Africa:': 912,\n",
              " 'hesitation': 913,\n",
              " 'puff': 914,\n",
              " 'Superdome': 915,\n",
              " 'shacks': 916,\n",
              " 'Kendalls': 917,\n",
              " 'Pins': 918,\n",
              " 'Barbecue': 919,\n",
              " '275': 920,\n",
              " '[refining]': 921,\n",
              " 'pectoral': 922,\n",
              " 'poly-cotton': 923,\n",
              " 'depopulating': 924,\n",
              " 'bliss': 925,\n",
              " 'visualizes': 926,\n",
              " 'PMTCT': 927,\n",
              " 'Comedy': 928,\n",
              " 'Wal-Mart;': 929,\n",
              " 'Linux': 930,\n",
              " 'blessings': 931,\n",
              " 'snacks': 932,\n",
              " 'skied': 933,\n",
              " 'quadrant': 934,\n",
              " 'transcendent': 935,\n",
              " 'renewing': 936,\n",
              " '12-foot': 937,\n",
              " 'Poldrack': 938,\n",
              " 'brags': 939,\n",
              " 'pub': 940,\n",
              " 'supplying': 941,\n",
              " 'buckle': 942,\n",
              " 'familiarity': 943,\n",
              " 'lacrosse': 944,\n",
              " 'work-specific': 945,\n",
              " 'sexologists': 946,\n",
              " 'peoples': 947,\n",
              " 'ex-husband': 948,\n",
              " 'scream': 949,\n",
              " 'comptete': 950,\n",
              " 'fine:': 951,\n",
              " 'magnetized': 952,\n",
              " 'browning': 953,\n",
              " 'Hudiksvall': 954,\n",
              " 'lays': 955,\n",
              " 'shortages': 956,\n",
              " 'democracy;': 957,\n",
              " 'buffing': 958,\n",
              " 'bankfrauds@yahoo': 959,\n",
              " 'East-to-West': 960,\n",
              " 'hermetic': 961,\n",
              " 'Royal': 962,\n",
              " 'beaker': 963,\n",
              " 'nuance': 964,\n",
              " 'West:': 965,\n",
              " 'open-space': 966,\n",
              " 'SLA': 967,\n",
              " 'readings': 968,\n",
              " 'footrace': 969,\n",
              " 'meatpacking': 970,\n",
              " 'Portsmouth': 971,\n",
              " 'spelling': 972,\n",
              " 'cupping': 973,\n",
              " 'cord-injured': 974,\n",
              " 'Gyeongbokgung': 975,\n",
              " 'hydroxyl': 976,\n",
              " 'all-night': 977,\n",
              " 'retirees': 978,\n",
              " 'peanuts': 979,\n",
              " '113': 980,\n",
              " '400-odd': 981,\n",
              " 'deriving': 982,\n",
              " 'unscientific': 983,\n",
              " 'half-hour;': 984,\n",
              " 'engine': 985,\n",
              " 'ejaculate': 986,\n",
              " 'materials;': 987,\n",
              " 'four-by-three': 988,\n",
              " 'testimonial': 989,\n",
              " 'replicating': 990,\n",
              " 'Rosenfeld:': 991,\n",
              " 'attrition': 992,\n",
              " 'Zenoune-Zouani': 993,\n",
              " 'Jones:': 994,\n",
              " 'Bjork': 995,\n",
              " 'coordinator': 996,\n",
              " 'inflection': 997,\n",
              " 'Ramon': 998,\n",
              " 'nostalagia': 999,\n",
              " 'Around]And': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymMxx_bPQYrF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72793011-1fd4-4f3e-fc3e-6908b03eb074"
      },
      "source": [
        "tag2idx"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'!': 2, ',': 1, '.': 4, '?': 0, 'O': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zXzE0MdsemCH"
      },
      "source": [
        "### Task 5: Padding Input Sentences and Creating Train/Test Splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R44g5T7NYp_H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5b1a6377-44d7-4c41-afec-be80c119b082"
      },
      "source": [
        "plt.hist([len(s) for s in sentences], bins=50)\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FS4u3CRkpkc1",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_len = 50\n",
        "\n",
        "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
        "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=num_words-1)\n",
        "\n",
        "y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
        "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q7VfnnkXpkfS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4822f6f7-3be6-4bbf-f310-d1de6f8559df"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "print(f\"Train size: {len(x_train)}, \\nTest size: {len(x_test)}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 1967, \n",
            "Test size: 492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P-r4PR85hpoF"
      },
      "source": [
        "### Task 6: Build and Compile a Bidirectional LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y2vM7IkXpkiH",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense\n",
        "from tensorflow.keras.layers import TimeDistributed, SpatialDropout1D, Bidirectional, Dropout"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Aee3mCZ3pkkv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "55f07d23-8b53-4a24-c664-33dfe79e38c0"
      },
      "source": [
        "input_word = Input(shape=(max_len,))\n",
        "model = Embedding(input_dim=num_words, output_dim=50, input_length=max_len)(input_word)\n",
        "# model = SpatialDropout1D(0.1)(model)\n",
        "model = Dropout(0.1)(model)\n",
        "model = Bidirectional(LSTM(units=200, return_sequences=True, recurrent_dropout=0.1))(model)\n",
        "out = TimeDistributed(Dense(num_tags, activation=\"softmax\"))(model)\n",
        "model = Model(input_word, out)\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 50, 50)            4368600   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 50)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 50, 400)           401600    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 50, 5)             2005      \n",
            "=================================================================\n",
            "Total params: 4,772,205\n",
            "Trainable params: 4,772,205\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kOBpQg26pkqh",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "My0tL0cciMXQ"
      },
      "source": [
        "### Task 7: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeykMJgKOxE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q9HWH06Ypkxh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "279f36c2-68b6-4754-aaa8-14872a8f317a"
      },
      "source": [
        "%%time\n",
        "\n",
        "chkpt = ModelCheckpoint(\"model_weights.h5\", monitor='val_loss',verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='min', baseline=None, restore_best_weights=False)\n",
        "\n",
        "callbacks = [chkpt, early_stopping]\n",
        "\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    validation_data=(x_test,y_test),\n",
        "    batch_size=32, \n",
        "    epochs=30,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.6846 - accuracy: 0.8321\n",
            "Epoch 00001: val_loss improved from inf to 0.54075, saving model to model_weights.h5\n",
            "62/62 [==============================] - 32s 514ms/step - loss: 0.6846 - accuracy: 0.8321 - val_loss: 0.5407 - val_accuracy: 0.8434\n",
            "Epoch 2/30\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.5080 - accuracy: 0.8498\n",
            "Epoch 00002: val_loss improved from 0.54075 to 0.46930, saving model to model_weights.h5\n",
            "62/62 [==============================] - 31s 505ms/step - loss: 0.5080 - accuracy: 0.8498 - val_loss: 0.4693 - val_accuracy: 0.8612\n",
            "Epoch 3/30\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.4089 - accuracy: 0.8644\n",
            "Epoch 00003: val_loss improved from 0.46930 to 0.39567, saving model to model_weights.h5\n",
            "62/62 [==============================] - 31s 499ms/step - loss: 0.4089 - accuracy: 0.8644 - val_loss: 0.3957 - val_accuracy: 0.8710\n",
            "Epoch 4/30\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.3094 - accuracy: 0.8940\n",
            "Epoch 00004: val_loss improved from 0.39567 to 0.30265, saving model to model_weights.h5\n",
            "62/62 [==============================] - 30s 490ms/step - loss: 0.3094 - accuracy: 0.8940 - val_loss: 0.3026 - val_accuracy: 0.9046\n",
            "Epoch 5/30\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.2267 - accuracy: 0.9247\n",
            "Epoch 00005: val_loss improved from 0.30265 to 0.27055, saving model to model_weights.h5\n",
            "62/62 [==============================] - 31s 500ms/step - loss: 0.2267 - accuracy: 0.9247 - val_loss: 0.2706 - val_accuracy: 0.9152\n",
            "Epoch 6/30\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.1910 - accuracy: 0.9372\n",
            "Epoch 00006: val_loss improved from 0.27055 to 0.26104, saving model to model_weights.h5\n",
            "62/62 [==============================] - 31s 499ms/step - loss: 0.1910 - accuracy: 0.9372 - val_loss: 0.2610 - val_accuracy: 0.9195\n",
            "Epoch 7/30\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.1715 - accuracy: 0.9430\n",
            "Epoch 00007: val_loss improved from 0.26104 to 0.25667, saving model to model_weights.h5\n",
            "62/62 [==============================] - 31s 499ms/step - loss: 0.1715 - accuracy: 0.9430 - val_loss: 0.2567 - val_accuracy: 0.9197\n",
            "Epoch 8/30\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.1566 - accuracy: 0.9481\n",
            "Epoch 00008: val_loss did not improve from 0.25667\n",
            "62/62 [==============================] - 31s 504ms/step - loss: 0.1566 - accuracy: 0.9481 - val_loss: 0.2603 - val_accuracy: 0.9166\n",
            "Epoch 9/30\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.1458 - accuracy: 0.9508\n",
            "Epoch 00009: val_loss did not improve from 0.25667\n",
            "62/62 [==============================] - 31s 500ms/step - loss: 0.1458 - accuracy: 0.9508 - val_loss: 0.2624 - val_accuracy: 0.9183\n",
            "CPU times: user 6min 55s, sys: 1min 2s, total: 7min 57s\n",
            "Wall time: 4min 49s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2nwnnF0ziU3B"
      },
      "source": [
        "### Task 8: Evaluate Punctuation Restoration Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6euqX7UHplG7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4772b745-14e7-44dc-f24a-5202f4197ffb"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 1s 45ms/step - loss: 0.2624 - accuracy: 0.9183\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2623521089553833, 0.9183333516120911]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tyg4mKOVplJ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "b7486517-482d-435d-ef2e-cbde4ff2fa0a"
      },
      "source": [
        "i = np.random.randint(0, x_test.shape[0])\n",
        "p = model.predict(np.array([x_test[i]]))\n",
        "p = np.argmax(p, axis=-1)\n",
        "y_true = y_test[i]\n",
        "print(\"{:15}{:5}\\t {}\\n\".format(\"Word\", \"True\", \"Pred\"))\n",
        "print(\"-\" *30)\n",
        "for w, true, pred in zip(x_test[i], y_true, p[0]):\n",
        "    print(\"{:15}{}\\t{}\".format(words[w-1], tags[true], tags[pred]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word           True \t Pred\n",
            "\n",
            "------------------------------\n",
            "longevity      O\t,\n",
            "there          O\tO\n",
            "is             O\tO\n",
            "no             O\tO\n",
            "short          O\tO\n",
            "term           O\tO\n",
            "fix            O\tO\n",
            "in             O\tO\n",
            "a              O\tO\n",
            "pill           O\tO\n",
            "or             O\tO\n",
            "anything       O\tO\n",
            "else           .\t.\n",
            "But            O\tO\n",
            "when           O\tO\n",
            "you            O\tO\n",
            "think          O\tO\n",
            "about          O\tO\n",
            "it             ,\tO\n",
            "your           O\tO\n",
            "friends        O\tO\n",
            "are            O\tO\n",
            "long-term      O\tO\n",
            "adventures     ,\t,\n",
            "and            O\tO\n",
            "therefore      ,\t,\n",
            "perhaps        O\tO\n",
            "the            O\tO\n",
            "most           O\tO\n",
            "significant    O\tO\n",
            "thing          O\tO\n",
            "you            O\tO\n",
            "can            O\tO\n",
            "do             O\tO\n",
            "to             O\tO\n",
            "add            O\tO\n",
            "more           O\tO\n",
            "years          O\tO\n",
            "to             O\tO\n",
            "your           O\tO\n",
            "life           ,\t,\n",
            "and            O\tO\n",
            "life           O\tO\n",
            "to             O\tO\n",
            "your           O\tO\n",
            "years          .\t.\n",
            "Thank          O\tO\n",
            "you            O\tO\n",
            "very           O\tO\n",
            "much           .\t.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Punctuation_Restoration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}