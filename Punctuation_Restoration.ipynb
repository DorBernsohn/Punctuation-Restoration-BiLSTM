{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q4gSqDnOaJ7W"
      },
      "source": [
        "<img align=center src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcT2RkpDnU0khR-RsIgLQcCKUMwM3EbWiFN_5Q&usqp=CAU\"></img>\n",
        "<h2 align=center> Punctuation Restoration using BiLSTMs with Keras</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4IU4QuHO33M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fdo8oAodagwo"
      },
      "source": [
        "### Task 1: Project Overview and Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oLK7Y1jiNXDa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b494d738-c5b8-4480-a830-66342d3ceec3"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(0)\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "print('Tensorflow version:', tf.__version__)\n",
        "print('GPU detected:', tf.config.list_physical_devices('GPU'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.2.0\n",
            "GPU detected: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4N_AW6lMbB5N"
      },
      "source": [
        "### Task 2: Load and Explore the TED transcription Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_4DvshIOxEB",
        "colab_type": "text"
      },
      "source": [
        "*Essential info about punctuation tags*:\n",
        "- , = comma\n",
        "- ! = exclamation mark\n",
        "- . = dot\n",
        "- ? = question mark\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bJ3EJiOZ4-H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "40a7c718-110a-4c2e-90da-257f53d60dca"
      },
      "source": [
        "transcript_df = pd.read_csv(\"/content/drive/My Drive/projects/Punctuation Restoration/transcripts.csv\", encoding=\"utf-8\")\n",
        "transcript_df = transcript_df.fillna(method=\"ffill\")\n",
        "transcript_df.head(20)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transcript</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Good morning. How are you?(Laughter)It's been ...</td>\n",
              "      <td>https://www.ted.com/talks/ken_robinson_says_sc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
              "      <td>https://www.ted.com/talks/al_gore_on_averting_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(Music: \"The Sound of Silence,\" Simon &amp; Garfun...</td>\n",
              "      <td>https://www.ted.com/talks/david_pogue_says_sim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you're here today — and I'm very happy that...</td>\n",
              "      <td>https://www.ted.com/talks/majora_carter_s_tale...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>About 10 years ago, I took on the task to teac...</td>\n",
              "      <td>https://www.ted.com/talks/hans_rosling_shows_t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Thank you. I have to tell you I'm both challen...</td>\n",
              "      <td>https://www.ted.com/talks/tony_robbins_asks_wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>On September 10, the morning of my seventh bir...</td>\n",
              "      <td>https://www.ted.com/talks/julia_sweeney_on_let...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>I'm going to present three projects in rapid f...</td>\n",
              "      <td>https://www.ted.com/talks/joshua_prince_ramus_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>It's wonderful to be back. I love this wonderf...</td>\n",
              "      <td>https://www.ted.com/talks/dan_dennett_s_respon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I'm often asked, \"What surprised you about the...</td>\n",
              "      <td>https://www.ted.com/talks/rick_warren_on_a_lif...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>I'm going to take you on a journey very quickl...</td>\n",
              "      <td>https://www.ted.com/talks/cameron_sinclair_on_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>I can't help but this wish: to think about whe...</td>\n",
              "      <td>https://www.ted.com/talks/jehane_noujaim_inspi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>I'm the luckiest guy in the world. I got to se...</td>\n",
              "      <td>https://www.ted.com/talks/larry_brilliant_want...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>I'm really excited to be here today. I'll show...</td>\n",
              "      <td>https://www.ted.com/talks/jeff_han_demos_his_b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>I've been at MIT for 44 years. I went to TED I...</td>\n",
              "      <td>https://www.ted.com/talks/nicholas_negroponte_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>(Music)(Music ends)(Applause)(Applause ends)Hi...</td>\n",
              "      <td>https://www.ted.com/talks/sirena_huang_dazzles...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>(Music)(Music ends)(Applause)Thank you!(Applau...</td>\n",
              "      <td>https://www.ted.com/talks/jennifer_lin_improvs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>In terms of invention, I'd like to tell you th...</td>\n",
              "      <td>https://www.ted.com/talks/amy_smith_shares_sim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>My name is Lovegrove. I only know nine Lovegro...</td>\n",
              "      <td>https://www.ted.com/talks/ross_lovegrove_share...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Charles Van Doren, who was later a senior edit...</td>\n",
              "      <td>https://www.ted.com/talks/jimmy_wales_on_the_b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           transcript                                                url\n",
              "0   Good morning. How are you?(Laughter)It's been ...  https://www.ted.com/talks/ken_robinson_says_sc...\n",
              "1   Thank you so much, Chris. And it's truly a gre...  https://www.ted.com/talks/al_gore_on_averting_...\n",
              "2   (Music: \"The Sound of Silence,\" Simon & Garfun...  https://www.ted.com/talks/david_pogue_says_sim...\n",
              "3   If you're here today — and I'm very happy that...  https://www.ted.com/talks/majora_carter_s_tale...\n",
              "4   About 10 years ago, I took on the task to teac...  https://www.ted.com/talks/hans_rosling_shows_t...\n",
              "5   Thank you. I have to tell you I'm both challen...  https://www.ted.com/talks/tony_robbins_asks_wh...\n",
              "6   On September 10, the morning of my seventh bir...  https://www.ted.com/talks/julia_sweeney_on_let...\n",
              "7   I'm going to present three projects in rapid f...  https://www.ted.com/talks/joshua_prince_ramus_...\n",
              "8   It's wonderful to be back. I love this wonderf...  https://www.ted.com/talks/dan_dennett_s_respon...\n",
              "9   I'm often asked, \"What surprised you about the...  https://www.ted.com/talks/rick_warren_on_a_lif...\n",
              "10  I'm going to take you on a journey very quickl...  https://www.ted.com/talks/cameron_sinclair_on_...\n",
              "11  I can't help but this wish: to think about whe...  https://www.ted.com/talks/jehane_noujaim_inspi...\n",
              "12  I'm the luckiest guy in the world. I got to se...  https://www.ted.com/talks/larry_brilliant_want...\n",
              "13  I'm really excited to be here today. I'll show...  https://www.ted.com/talks/jeff_han_demos_his_b...\n",
              "14  I've been at MIT for 44 years. I went to TED I...  https://www.ted.com/talks/nicholas_negroponte_...\n",
              "15  (Music)(Music ends)(Applause)(Applause ends)Hi...  https://www.ted.com/talks/sirena_huang_dazzles...\n",
              "16  (Music)(Music ends)(Applause)Thank you!(Applau...  https://www.ted.com/talks/jennifer_lin_improvs...\n",
              "17  In terms of invention, I'd like to tell you th...  https://www.ted.com/talks/amy_smith_shares_sim...\n",
              "18  My name is Lovegrove. I only know nine Lovegro...  https://www.ted.com/talks/ross_lovegrove_share...\n",
              "19  Charles Van Doren, who was later a senior edit...  https://www.ted.com/talks/jimmy_wales_on_the_b..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKmDzK9qaTKb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "5ae34463-9ff2-4cc4-eb99-8d26bab79fc8"
      },
      "source": [
        "%time transcript_df.transcript = transcript_df.transcript.apply(lambda x: re.sub(r'\\([^)]*\\)', ' ', x))\n",
        "%time transcript_df.transcript = transcript_df.transcript.apply(lambda x: re.sub(r'(?<=[.,?!])(?=[^\\s])', ' ', x))\n",
        "%time transcript_df.transcript = transcript_df.transcript.apply(lambda x: x.replace('\"', ''))\n",
        "%time transcript_df.transcript = transcript_df.transcript.apply(lambda x: x.replace(\"'\", ''))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 47.1 ms, sys: 16.8 ms, total: 64 ms\n",
            "Wall time: 64.4 ms\n",
            "CPU times: user 729 ms, sys: 7.05 ms, total: 736 ms\n",
            "Wall time: 740 ms\n",
            "CPU times: user 37.3 ms, sys: 3.04 ms, total: 40.3 ms\n",
            "Wall time: 40.1 ms\n",
            "CPU times: user 35.1 ms, sys: 5.97 ms, total: 41.1 ms\n",
            "Wall time: 41 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS3f99lYbXDN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "93706623-21b2-412f-a58f-45ff9fa8da3b"
      },
      "source": [
        "text_list = []\n",
        "sentence_list = []\n",
        "word_list = []\n",
        "\n",
        "start = datetime.now()\n",
        "for i, sentence in tqdm(enumerate(transcript_df.transcript)):\n",
        "  for word in sentence.split():\n",
        "      sentence_list.append(f\"Sentence: {i}\")\n",
        "      if word.endswith(','):\n",
        "          word_list.append(word[:-1])\n",
        "          text_list.append(',')\n",
        "      elif word.endswith('.'):\n",
        "          word_list.append(word[:-1])\n",
        "          text_list.append('.')\n",
        "      elif word.endswith('?'):\n",
        "          word_list.append(word[:-1])\n",
        "          text_list.append('?')\n",
        "      elif word.endswith('!'):\n",
        "          word_list.append(word[:-1])\n",
        "          text_list.append('!')\n",
        "      else:\n",
        "          word_list.append(word)\n",
        "          text_list.append('O')\n",
        "\n",
        "print(f\"Time taken: {datetime.now() - start}\")\n",
        "data = pd.DataFrame({'Sentence #': sentence_list, 'Word': word_list, 'Tag': text_list})\n",
        "print(f\"Dataset shape: {data.shape}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2467it [00:06, 410.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken: 0:00:06.010795\n",
            "Dataset shape: (5086851, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "riOztP-8NXHT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ffe51ecb-e8ec-4246-d09b-1a59f4d38d62"
      },
      "source": [
        "print(\"Unique words in corpus:\", data['Word'].nunique())\n",
        "print(\"Unique tags in corpus:\", data['Tag'].nunique())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique words in corpus: 87371\n",
            "Unique tags in corpus: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYrgeuYHOxEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = list(set(data[\"Word\"].values))\n",
        "words.append(\"ENDPAD\")\n",
        "num_words = len(words)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQH6yutfOxEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tags = list(set(data[\"Tag\"].values))\n",
        "num_tags = len(tags)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M9D9JEzUbdnS"
      },
      "source": [
        "### Task 3: Retrieve Sentences and Corresponsing Tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VdJst_g5NYY_",
        "colab": {}
      },
      "source": [
        "class SentenceGetter(object):\n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                           s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nMUQLppspkPj",
        "colab": {}
      },
      "source": [
        "getter = SentenceGetter(data)\n",
        "sentences = getter.sentences"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GhiSTt2UdzYC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "1b158995-1ec4-4b90-e1b7-f6a379a2431c"
      },
      "source": [
        "sentences[0][:20]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Good', 'O'),\n",
              " ('morning', '.'),\n",
              " ('How', 'O'),\n",
              " ('are', 'O'),\n",
              " ('you', '?'),\n",
              " ('Its', 'O'),\n",
              " ('been', 'O'),\n",
              " ('great', ','),\n",
              " ('hasnt', 'O'),\n",
              " ('it', '?'),\n",
              " ('Ive', 'O'),\n",
              " ('been', 'O'),\n",
              " ('blown', 'O'),\n",
              " ('away', 'O'),\n",
              " ('by', 'O'),\n",
              " ('the', 'O'),\n",
              " ('whole', 'O'),\n",
              " ('thing', '.'),\n",
              " ('In', 'O'),\n",
              " ('fact', ',')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ldhuogX4eHE4"
      },
      "source": [
        "### Task 4: Define Mappings between Sentences and Tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SvENHO18pkaQ",
        "colab": {}
      },
      "source": [
        "word2idx = {w: i + 1 for i, w in enumerate(words)}\n",
        "tag2idx = {t: i for i, t in enumerate(tags)}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymMxx_bPQYrF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72793011-1fd4-4f3e-fc3e-6908b03eb074"
      },
      "source": [
        "tag2idx"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'!': 2, ',': 1, '.': 4, '?': 0, 'O': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zXzE0MdsemCH"
      },
      "source": [
        "### Task 5: Padding Input Sentences and Creating Train/Test Splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R44g5T7NYp_H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5b1a6377-44d7-4c41-afec-be80c119b082"
      },
      "source": [
        "plt.hist([len(s) for s in sentences], bins=50)\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FS4u3CRkpkc1",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_len = 50\n",
        "\n",
        "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
        "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=num_words-1)\n",
        "\n",
        "y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
        "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q7VfnnkXpkfS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4822f6f7-3be6-4bbf-f310-d1de6f8559df"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "print(f\"Train size: {len(x_train)}, \\nTest size: {len(x_test)}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 1967, \n",
            "Test size: 492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P-r4PR85hpoF"
      },
      "source": [
        "### Task 6: Build and Compile a Bidirectional LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y2vM7IkXpkiH",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense\n",
        "from tensorflow.keras.layers import TimeDistributed, SpatialDropout1D, Bidirectional, Dropout"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Aee3mCZ3pkkv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "55f07d23-8b53-4a24-c664-33dfe79e38c0"
      },
      "source": [
        "input_word = Input(shape=(max_len,))\n",
        "model = Embedding(input_dim=num_words, output_dim=50, input_length=max_len)(input_word)\n",
        "# model = SpatialDropout1D(0.1)(model)\n",
        "model = Dropout(0.1)(model)\n",
        "model = Bidirectional(LSTM(units=200, return_sequences=True, recurrent_dropout=0.1))(model)\n",
        "out = TimeDistributed(Dense(num_tags, activation=\"softmax\"))(model)\n",
        "model = Model(input_word, out)\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 50, 50)            4368600   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 50)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 50, 400)           401600    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 50, 5)             2005      \n",
            "=================================================================\n",
            "Total params: 4,772,205\n",
            "Trainable params: 4,772,205\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kOBpQg26pkqh",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "My0tL0cciMXQ"
      },
      "source": [
        "### Task 7: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeykMJgKOxE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q9HWH06Ypkxh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "279f36c2-68b6-4754-aaa8-14872a8f317a"
      },
      "source": [
        "%%time\n",
        "\n",
        "chkpt = ModelCheckpoint(\"model_weights.h5\", monitor='val_loss',verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='min', baseline=None, restore_best_weights=False)\n",
        "\n",
        "callbacks = [chkpt, early_stopping]\n",
        "\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    validation_data=(x_test,y_test),\n",
        "    batch_size=32, \n",
        "    epochs=30,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.6846 - accuracy: 0.8321\n",
            "Epoch 00001: val_loss improved from inf to 0.54075, saving model to model_weights.h5\n",
            "62/62 [==============================] - 32s 514ms/step - loss: 0.6846 - accuracy: 0.8321 - val_loss: 0.5407 - val_accuracy: 0.8434\n",
            "Epoch 2/30\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.5080 - accuracy: 0.8498\n",
            "Epoch 00002: val_loss improved from 0.54075 to 0.46930, saving model to model_weights.h5\n",
            "62/62 [==============================] - 31s 505ms/step - loss: 0.5080 - accuracy: 0.8498 - val_loss: 0.4693 - val_accuracy: 0.8612\n",
            "Epoch 3/30\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.4089 - accuracy: 0.8644\n",
            "Epoch 00003: val_loss improved from 0.46930 to 0.39567, saving model to model_weights.h5\n",
            "62/62 [==============================] - 31s 499ms/step - loss: 0.4089 - accuracy: 0.8644 - val_loss: 0.3957 - val_accuracy: 0.8710\n",
            "Epoch 4/30\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.3094 - accuracy: 0.8940\n",
            "Epoch 00004: val_loss improved from 0.39567 to 0.30265, saving model to model_weights.h5\n",
            "62/62 [==============================] - 30s 490ms/step - loss: 0.3094 - accuracy: 0.8940 - val_loss: 0.3026 - val_accuracy: 0.9046\n",
            "Epoch 5/30\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.2267 - accuracy: 0.9247\n",
            "Epoch 00005: val_loss improved from 0.30265 to 0.27055, saving model to model_weights.h5\n",
            "62/62 [==============================] - 31s 500ms/step - loss: 0.2267 - accuracy: 0.9247 - val_loss: 0.2706 - val_accuracy: 0.9152\n",
            "Epoch 6/30\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.1910 - accuracy: 0.9372\n",
            "Epoch 00006: val_loss improved from 0.27055 to 0.26104, saving model to model_weights.h5\n",
            "62/62 [==============================] - 31s 499ms/step - loss: 0.1910 - accuracy: 0.9372 - val_loss: 0.2610 - val_accuracy: 0.9195\n",
            "Epoch 7/30\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.1715 - accuracy: 0.9430\n",
            "Epoch 00007: val_loss improved from 0.26104 to 0.25667, saving model to model_weights.h5\n",
            "62/62 [==============================] - 31s 499ms/step - loss: 0.1715 - accuracy: 0.9430 - val_loss: 0.2567 - val_accuracy: 0.9197\n",
            "Epoch 8/30\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.1566 - accuracy: 0.9481\n",
            "Epoch 00008: val_loss did not improve from 0.25667\n",
            "62/62 [==============================] - 31s 504ms/step - loss: 0.1566 - accuracy: 0.9481 - val_loss: 0.2603 - val_accuracy: 0.9166\n",
            "Epoch 9/30\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.1458 - accuracy: 0.9508\n",
            "Epoch 00009: val_loss did not improve from 0.25667\n",
            "62/62 [==============================] - 31s 500ms/step - loss: 0.1458 - accuracy: 0.9508 - val_loss: 0.2624 - val_accuracy: 0.9183\n",
            "CPU times: user 6min 55s, sys: 1min 2s, total: 7min 57s\n",
            "Wall time: 4min 49s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2nwnnF0ziU3B"
      },
      "source": [
        "### Task 8: Evaluate Punctuation Restoration Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6euqX7UHplG7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4772b745-14e7-44dc-f24a-5202f4197ffb"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 1s 45ms/step - loss: 0.2624 - accuracy: 0.9183\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2623521089553833, 0.9183333516120911]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tyg4mKOVplJ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "b7486517-482d-435d-ef2e-cbde4ff2fa0a"
      },
      "source": [
        "i = np.random.randint(0, x_test.shape[0])\n",
        "p = model.predict(np.array([x_test[i]]))\n",
        "p = np.argmax(p, axis=-1)\n",
        "y_true = y_test[i]\n",
        "print(\"{:15}{:5}\\t {}\\n\".format(\"Word\", \"True\", \"Pred\"))\n",
        "print(\"-\" *30)\n",
        "for w, true, pred in zip(x_test[i], y_true, p[0]):\n",
        "    print(\"{:15}{}\\t{}\".format(words[w-1], tags[true], tags[pred]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word           True \t Pred\n",
            "\n",
            "------------------------------\n",
            "longevity      O\t,\n",
            "there          O\tO\n",
            "is             O\tO\n",
            "no             O\tO\n",
            "short          O\tO\n",
            "term           O\tO\n",
            "fix            O\tO\n",
            "in             O\tO\n",
            "a              O\tO\n",
            "pill           O\tO\n",
            "or             O\tO\n",
            "anything       O\tO\n",
            "else           .\t.\n",
            "But            O\tO\n",
            "when           O\tO\n",
            "you            O\tO\n",
            "think          O\tO\n",
            "about          O\tO\n",
            "it             ,\tO\n",
            "your           O\tO\n",
            "friends        O\tO\n",
            "are            O\tO\n",
            "long-term      O\tO\n",
            "adventures     ,\t,\n",
            "and            O\tO\n",
            "therefore      ,\t,\n",
            "perhaps        O\tO\n",
            "the            O\tO\n",
            "most           O\tO\n",
            "significant    O\tO\n",
            "thing          O\tO\n",
            "you            O\tO\n",
            "can            O\tO\n",
            "do             O\tO\n",
            "to             O\tO\n",
            "add            O\tO\n",
            "more           O\tO\n",
            "years          O\tO\n",
            "to             O\tO\n",
            "your           O\tO\n",
            "life           ,\t,\n",
            "and            O\tO\n",
            "life           O\tO\n",
            "to             O\tO\n",
            "your           O\tO\n",
            "years          .\t.\n",
            "Thank          O\tO\n",
            "you            O\tO\n",
            "very           O\tO\n",
            "much           .\t.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Punctuation_Restoration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}